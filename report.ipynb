{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb590f55",
   "metadata": {},
   "source": [
    "# <center> DEEP LEARNING ALGORITHMS FOR TIME SERIES ANALYSIS WITH APPLICATIONS <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace49df4",
   "metadata": {},
   "source": [
    "**İpek Korkmaz** - ipekkorkmz@gmail.com  \n",
    "**Eda Atalay** - edaatalay99@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce115a3d-239f-4699-8924-4833f0ad1332",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#351C75\">Table of Contents:</span>\n",
    "\n",
    "[1. INTRODUCTION](#1.-INTRODUCTION)  \n",
    "[2. AN OVERVIEW OF DEEP LEARNING](#2.-AN-OVERVIEW-OF-DEEP-LEARNING)  \n",
    "[3. NEURAL NETWORKS](#3.-NEURAL-NETWORKS)  \n",
    "&emsp;[3.1. Single Layer Neural Networks](#3.1.-Single-Layer-Neural-Networks)  \n",
    "&emsp;&emsp;[3.1.1. Activation Function](#3.1.1.-Activation-Function)  \n",
    "&emsp;&emsp;&emsp;[3.1.1.1. Sigmoid Activation Function](#3.1.1.1.-Sigmoid-Activation-Function)  \n",
    "&emsp;&emsp;&emsp;[3.1.1.2. ReLU Activation Function](#3.1.1.2.-ReLU-Activation-Function)  \n",
    "&emsp;&emsp;[3.1.2. Squared-Error Loss](#3.1.2.-Squared-Error-Loss)  \n",
    "&emsp;[3.2. Multilayer Neural Networks](#3.2.-Multilayer-Neural-Networks)  \n",
    "[4. RECURRENT NEURAL NETWORKS (RNN)](#4.-RECURRENT-NEURAL-NETWORKS-(RNN))  \n",
    "&emsp;[4.1. Disadvantages of Recurrent Neural Networks](#4.1.-Disadvantages-of-Recurrent-Neural-Networks)  \n",
    "[5. LONG SHORT-TERM MEMORY (LSTM)](#5.-LONG-SHORT-TERM-MEMORY-(LSTM))  \n",
    "&emsp;[5.1. Cell State](#5.1.-Cell-State)  \n",
    "&emsp;[5.2. Gates](#5.2.-Gates)  \n",
    "&emsp;&emsp;[5.2.1. Forget Gates](#5.2.1.-Forget-Gates)  \n",
    "&emsp;&emsp;[5.2.2. Input Gates](#5.2.2.-Input-Gates)  \n",
    "&emsp;&emsp;[5.2.3. Output Gates](#5.2.3.-Output-Gates)  \n",
    "[6. MODEL BUILDING](#6.-MODEL-BUILDING)  \n",
    "&emsp;[6.1. The Libraries Used](#6.1.-The-Libraries-Used)  \n",
    "&emsp;[6.2. The Dataset](#6.2.-The-Dataset)  \n",
    "&emsp;[6.3. Data Wrangling](#6.3.-Data-Wrangling)  \n",
    "&emsp;[6.4. Models](#6.4.-Models)  \n",
    "&emsp;&emsp;[6.4.1. LSTM Models](#6.4.1.-LSTM-Models)  \n",
    "&emsp;&emsp;&emsp;[6.4.1.1. LSTM Base Model](#6.4.1.1.-LSTM-Base-Model)  \n",
    "&emsp;&emsp;&emsp;[6.4.1.2. LSTM Model Using One Hot Encoding](#6.4.1.2.-LSTM-Model-Using-One-Hot-Encoding)  \n",
    "&emsp;&emsp;&emsp;[6.4.1.3. LSTM Model Using Label Encoding](#6.4.1.3.-LSTM-Model-Using-Label-Encoding)   \n",
    "&emsp;&emsp;[6.4.2. Feed-Forward Neural Network Models](#6.4.2.-Feed-Forward-Neural-Network-Models)  \n",
    "&emsp;&emsp;&emsp;[6.4.2.1. Feed-Forward Neural Network Base Model](#6.4.2.1.-Feed-Forward-Neural-Network-Base-Model)  \n",
    "&emsp;&emsp;&emsp;[6.4.2.2. Feed-Forward Neural Network Model Using One Hot Encoding](#6.4.2.2.-Feed-Forward-Neural-Network-Model-Using-One-Hot-Encoding)  \n",
    "&emsp;&emsp;&emsp;[6.4.2.3. Feed-Forward Neural Network Model Using Label Encoding](#6.4.2.3.-Feed-Forward-Neural-Network-Model-Using-Label-Encoding)  \n",
    "&emsp;[6.5 Model Comparison](#6.5-Model-Comparison)  \n",
    "[7. CONCLUSION](#7.-CONCLUSION)  \n",
    "[REFERENCES](#REFERENCES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275ebcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#351C75\">1. INTRODUCTION</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c23f2",
   "metadata": {},
   "source": [
    "Nowadays, more and more data are collected every day and it is critical to be able to construct meaning from the data. Forecasting has an important part in a variety of fields as a result of the technology advancement. Making predictions and decisions around the unknown future is a topic that is necessary in our complex world, especially when it comes to economics.\n",
    "\n",
    "In this project, feed-forward neural networks and recurrent neural networks, which are a subject of deep learning was thoroughly examined. For a better understanding of deep learning, literature research has been done and the history of deep learning was discussed. In the project, especially the mathematical relationships and the related equations were presented. Also, a special type of recurrent neural network for time series, LSTM was explored in depth.\n",
    "\n",
    "In application, the data set containing 44 county pairs, export values for each country pair, and several factors that may affect export values, was examined. The dataset and the meaning of those factors were thoroughly discussed.\n",
    "\n",
    "The main purpose of the project is to investigate export values change over time and to predict the future. For that reason, several models have been built on Python. Three models have been built using LSTM and the other three models have been built with feed-forward neural network. In order to determine the optimal model for data set, model error values have been compared and regarding this comparison, the discussion has been made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce10f2e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">2. AN OVERVIEW OF DEEP LEARNING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1108b2",
   "metadata": {},
   "source": [
    "The history of deep learning goes back to McCulloch & Pitts paper published in 1943. According to the study, what makes a human brain a computational device is the neural activity in the mind.[[1]](https://www.annualreviews.org/doi/10.1146/annurev-statistics-041715-033733) Taking this into consideration, deep learning algorithms have been influenced by human brains, which can understand complicated information.\n",
    "\n",
    "If a network has enough number of neurons and has a proper synaptic connection, then it can compute any value. In this case, a simple logic function will be applied depending on the weights in the McCulloch & Pitts neuron. Furthermore, the concept of threshold is an important feature. For a precise neuron, if the net input which is the weighted sum of the inputs is greater than a certain threshold then the neuron will be fired.\n",
    "\n",
    "In 1949, Hebb published a book called “The Organization of Behavior”. Hebb suggested that the brain's connectivity is constantly changing as an organism while learning different functional tasks. The idea behind Hebb's theory is that if two neurons are found to be active at the same time, fired together, the strength of the connection between them should be increased. [[2]](https://books.google.com.tr/books?hl=tr&lr=&id=jJTN8RPgyXgC&oi=fnd&pg=PR21&dq=S.N.+Sivanandam,+S.+Sumathi,+S.N.+Deepa,+Introduction+to+Neural+Networks+Using+Matlab+6.0+(McGraw+Hill+Education+(India)+Private+Ltd.,+2006)%0A&ots=h1cxOQLyOJ&sig=OWBFNKIPYtnu2uqKPioDly-9oXA&redir_esc=y#v=onepage&q&f=false) The strength of the connection between neurons will be changed while learning.\n",
    "\n",
    "Tasks such as learning to classify labeled examples and recognition of distinct patterns were performed by the term called perceptron. Perceptron is the method for iterative weight arrangement, therefore the weights on the connection paths can be improved. Rosenblatt proved a theorem that the learning algorithm can find the right answer if there was a sufficient set of parameters for classifying and there were adequate number of examples. However, in the 1950s the perceptron learning algorithm was needed for digital computers to compute with real numbers which were carried out insufficiently at that time.\n",
    "\n",
    "Deep learning networks allow communication between computers and human beings while being a bridge between digital and daily life. In other words, it provides a balance between real word which is complex and indefinite with a word with symbols and rules.[[3]](https://www.pnas.org/content/117/48/30033Ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455a3e8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">3. NEURAL NETWORKS</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b798ce2",
   "metadata": {},
   "source": [
    "In this section, we closely followed the book titled “An Introduction to Statistical Learning with Application in R” by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. Additionally, all figures in this chapter are taken from the book.[[4]](https://www.statlearning.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cf9af",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">3.1. Single Layer Neural Networks</span>"
   ]
  },
  {
   "attachments": {
    "c2b59e8c-5fe3-4842-8f68-91775b080b80.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsK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\nFFFFAH//2Q==\n"
    }
   },
   "cell_type": "markdown",
   "id": "6d7a959e",
   "metadata": {},
   "source": [
    "For predicting the response $𝑌$, a neural network will build nonlinear function $\\vec{X}$ &rarr; $𝑌$ where $𝑋$ is input vector of n number of variables $\\vec{X} = (X_1 + X_2 + ... + X_n)$.  These input units will affect the model’s result.\n",
    "\n",
    "![_Figure 1: Neural network with single layer_](attachment:c2b59e8c-5fe3-4842-8f68-91775b080b80.jpg)\n",
    "\n",
    "*Figure 1* shows feed-forward neural network with single layer. The input vector $\\vec{X}$ will create input layer neurons in the neural network. Each unit from the input layer will feed the hidden layer network which has K hidden units. In this layer, the units are neither inputs nor outputs, that is why it is called hidden. \n",
    "\n",
    "$$ f(X) = \\beta_0 + \\sum_{k=1}^{K} \\beta_kh_k(X) $$\n",
    "\n",
    "In Equations above, $\\small w_{11},…,w_{nK}$ indicate weights flow through input layer to hidden layer. Similarly, $\\small β_1,β_2,…,β_K$ indicate weights flow through hidden layer to output. $\\small β_0$ and $\\small w_{0k}$ are the bias terms. First index of $\\small w$ shows that which neuron in the input layer will feed into the hidden layer. Second index of $\\small w$ shows which neuron in the hidden layer feeded up.\n",
    "\n",
    "$\\smallβ$  and $\\small w$ parameters must be estimated from data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d19b0-1ede-4d6a-882d-1210ec71ddf3",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">3.1.1. Activation Function</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63ce2c-aeae-46be-91a1-3521e7ffcc36",
   "metadata": {},
   "source": [
    "Nonlinearity is included to a neuron through activation function that is crucial for finding a solution of complex neural network problems. If nonlinearity in the activation function is not applied, network model turns into a simple linear regression model. Also, the nonlinearity of the activation function provides better reflection of complex data.\n",
    "\n",
    "$\\small A_k$ are the neurons in the hidden layer. $\\small h_k (X)$ is the function that builds $\\small A_k$ with input features. $\\small g(t)$ is an activation function that is nonlinear in advance:  \n",
    "$$A_k= h_k(X)=g(w_{0k}+\\sum_{i=1}^nw_{ik} X_i).$$\n",
    "$\\small f(X)$  function will be computed with weights $\\small β_k$ and the activations $\\small A_k$ from hidden layer pass into the output layer: \n",
    "\n",
    "$$f(X)= β_0+\\sum_{k=1}^Kβ_k A_{k}. $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40839669-7906-4abf-843d-15bd36bff98f",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">3.1.1.1. Sigmoid Activation Function</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681044f1-feec-4362-9ede-7d3c37554c44",
   "metadata": {},
   "source": [
    "Sigmoid activation function was used as a default activation function for neural network until the early 1990s. It scales input values between 0 and 1,  \n",
    "$$g(t)=  \\frac{e^t}{(1+ e^t )}=  \\frac{1}{(1+ e^{-t})}.$$  \n",
    "Only changes around the mid-point are sensitive to the functions as seen in _Figure 2_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408ca69-808d-463b-9038-3af4ac4f0142",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">3.1.1.2. ReLU Activation Function</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ec458-15ff-429e-8b46-824d242d95ce",
   "metadata": {},
   "source": [
    "The rectified linear activation function (ReLU) is a piecewise function that when input value is positive it equals to itself, or else it equals to 0. If the input value is positive ReLU function is linear, or else it is nonlinear. The ReLU function is more sensitive than sigmoid function.  \n",
    "\\begin{equation}\n",
    "g(t)=(t)_{+}= \n",
    "\\begin{cases} \n",
    "0         & \\text{if } t < 0 \\\\\n",
    "t         & \\text{otherwise } \n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "<center>![_Figure 2:Sigmoid and ReLU activation functions, respectively_](images/picture2.jpg)</center>  \n",
    "Earlier, sigmoid activation function was preferred, but today, ReLU activation function is common in modern neural networks because it is more powerful to compute and store.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b0522-0c3b-42fc-acbb-c511a7405b74",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">3.1.2. Squared-Error Loss</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f26ab1-0a6f-4b77-a649-9b52fe39ba61",
   "metadata": {
    "tags": []
   },
   "source": [
    "Squared error function is commonly used to estimate efficiency of the neural network model. It is used to compare the predicted value with the actual value where $\\small f(x_i)$ is the prediction and $\\small y_i$ is the $\\small i^{th}$ observation. The unknown parameters such as biases and weights are determined to minimize\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-f(x_i ))^2,$$  \n",
    "while fitting the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f32ca-7cce-48dd-9259-6a76b929bbfd",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">3.2. Multilayer Neural Networks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bda8f0-9c31-4715-a8e0-2d4f5c7d9c32",
   "metadata": {},
   "source": [
    "A large size single hidden layer is theoretically sufficient to make an acceptable approximation. Nevertheless, more than one hidden layer with small size returns good results much more easily.  \n",
    "<center>![_Figure 3: Neural network with two hidden layers, p number of outputs and weight matrices $\\small W_1$ ,$\\small W_2$,B_.](images/picture3.jpg)</center>  \n",
    "\n",
    "Apart from the number of layers, the difference between _Figure 1_ and _Figure 3_ is the number of results. In single layer neural network there were one output, however in this example, in two hidden layer neural network there are p number of outputs. Nevertheless, it is not necessary to have multiple outputs.\n",
    "\n",
    "Similarly to single layer neural network, the activation function applied from input layer to first hidden layer:\n",
    "\n",
    "$$A_k^{(1)}  = h_k^{(1)}(X) = g(w_{0k}^{(1)}+\\sum_{i=1}^nw_{ik}^{(1)} X_i), $$  \n",
    "for $\\small k=1,2,…,K_1.$  \n",
    "\n",
    "First hidden layer activations $\\small A_k^{(1)}$ will be treated as inputs for the second hidden layer activations:   \n",
    "$$A_l^{(2)}  = h_l^{(2)}(X) = g(w_{0l}^{(2)}+\\sum_{k=1}^{K_1}w_{kl}^{(2)} A_k^{(1)})$$  \n",
    "for $\\small l=1,2,…,K_2.$  \n",
    "\n",
    "Each of the activation functions, are function of $\\small \\vec{X}$ input vector. After sequences of transformations, the network will generate complex $\\small \\vec{X}$ transformations which are fed as features into the output layer.  \n",
    "\n",
    "At the output layer there are p number of results. The function is \n",
    "$$f_m (X)=β_{0m}+\\sum_{l=1}^{K_2}β_{lm}h_l^{(2)}(X)=β_{0m}+\\sum_{l=1}^{K_2}β_{lm}A_l^{(2)},$$\n",
    "while $\\small m=1,2,…,p$ if all these results are different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b9c99-ce1c-4b41-9b6b-3eb078d1247e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">4. RECURRENT NEURAL NETWORKS (RNN)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f538b8-400d-4388-b824-ff0d37c288b1",
   "metadata": {},
   "source": [
    "While working with documents, such as reviews and articles, or time-series data; remembering previous words or values might be necessary. In such cases, it is important to not start from scratch each time. Therefore, understanding previous data points is crucial. Recurrent neural networks (RNNs) allow information to carry on using loops. The feed-forward neural networks are meant for independent data points, and they are not capable of holding previous information. \n",
    "<center>![_Figure 3: Schematic of a simple recurrent neural network._](images/picture3.jpg)</center>\n",
    "\n",
    "In _Figure 3_, $\\small \\{X_l\\}_1^L$ are the sequence of input vectors and $\\small Y$ is the target which is a single response. The recurrent neural network will sequentially go through input sequence $\\small X$. Each input $\\small X_l$ will feed into the hidden layer such as a feed-forward neural network. The difference between feed-forward and recurrent neural networks is the hidden layer $\\small A_l$ will also take the activation function $\\small A_{l-1}$  from the previous step as input. **W,U** and **B** weights used when each of the elements was processed. At each step, $\\small O_l$ will be created from each activation function $\\small A_l$. The $\\small O_L$ is the most relevant one since the target single response will be the result of the last step $\\small O_L$.  \n",
    "\n",
    "$\\small X_l$ has $\\small p$ units and hidden layer has $\\small K$ units:  \n",
    "$$X_l^T  = (X_{l1},X_{l2},...,X_{lp}),$$  \n",
    "$$A_l^T= (A_{l1},A_{l2},...,A_{lK}).$$  \n",
    "Then the main equation for each activation function will follow \n",
    "\n",
    "$$A_{lk}  = g (w_{k0}+\\sum_{j=1}^pw_{kj}X_{lj}+\\sum_{s=1}^Ku_{ks} A_{l-1,s}),$$  \n",
    "and the $\\small O_l$ output for each layer will be calculated as  \n",
    "$$O_l  = β_0+\\sum_{k=1}^Kβ_kA_{lk}.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76167e-13c8-444b-919c-646c2ad26f93",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">4.1. Disadvantages of Recurrent Neural Networks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36372ac8-8762-415d-987d-1bd5f5a39157",
   "metadata": {},
   "source": [
    "Each weight in the network is updated using stochastic gradient descent. By taking the first prediction error of the model, it estimates a gradient. This gradient updates the weights so that less error is made next time, and it goes through the network from the output layer to the input layer. This process is called backward propagation.\n",
    "\n",
    "In most cases, it is desirable to work with many layers in a neural network since it presents better learning from large training datasets and increases on capacity of the network. However, when propagated backward through the network the gradient vanishes since there are many layers. When a gradient value becomes extremely small, it no longer contributes to learning.\n",
    "\n",
    "The equation of gradient descent algorithm will follow  \n",
    "$$w^+=w- α\\frac{∂Error}{∂w},$$  \n",
    "where $\\small w^+$ is updated weight, $\\small w$ is weight, $\\small α$ is learning rate, $\\small \\frac{∂Error}{∂w}$  is the gradient.  \n",
    "\n",
    "In recurrent neural networks (RNNs), because of the small gradient, earlier layers of the network will stop learning. In this case, the first layers of the network will not learn and RNN will forget what the first inputs are, which are expressed as short-term memory. Therefore, using RNN might not be desirable.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7647510-6356-41d8-bd49-1a2d0947e0ee",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">5. LONG SHORT-TERM MEMORY (LSTM)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85171057-5e36-4991-9a21-fd228f16b8d1",
   "metadata": {},
   "source": [
    "In this section, we closely followed the blog titled “Understanding LSTM Networks” by Christopher Olah. Additionally, all figures in this chapter are taken from the blog.\n",
    "\n",
    "Long Short-Term Memory (LSTM), which is a type of recurrent neural network, is broadly similar to the logic gates of a computer. LSTM can prevent long-term dependency problems with the concept of “memory cell”. In the RNN structure, there is only one activation function as seen in _Figure 4_. \n",
    "<center>![_Figure 4: RNN cell structure_](images/picture4.jpg)</center>\n",
    "\n",
    "However, the LSTM structure is more complex than RNNs as in _Figure 5_. An LSTM cell includes three gates called input gate, forget gate, output gate, and one cell state. Additionally, there are two activation function such as tanh and sigmoid.  \n",
    "<center>![_Figure 5: LSTM cell structure_](images/picture5.jpg)</center>\n",
    "\n",
    "The sigmoid function scales values between 0 and 1,\n",
    "$$σ(x)=  \\frac{e^x}{(1+ e^x)}=  \\frac{1}{(1+ e^{-x})}.$$  \n",
    "The tanh function scales values between -1 and 1,\n",
    "$$tanh(x) = \\frac{e^x-e^{-x}}{e^x+ e^{-x}}.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9691d7-6576-4cb0-867a-fc140258a4c3",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">5.1. Cell State</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e505734-0a95-4a18-b262-7c662fd5264a",
   "metadata": {},
   "source": [
    "The key part of the LSTM is the horizontal line flowing through the cell which is called cell state as seen in _Figure 6_. The flowing information can be removed, or new information can be added to the cell state by the term called gates. The gates will have outputs, and the cell state will be updated according to these outputs by the flow ability.\n",
    "\n",
    "<center>![_Figure 6: The cell state_](images/picture6.jpg)</center>\n",
    "\n",
    "<center><p>$\\small C_{t-1}:$ previous cell state,\n",
    "$\\small C_t:$ current cell state </p> </center>  \n",
    "$\\small C_{t-1}$ is the cell state that coming from the previous cell.\n",
    "This  $\\small C_{t-1}$  will updated through current cell and will give the new cell state $\\small C_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b1d28-1327-4941-894e-1f2ed2e38f65",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">5.2. Gates</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf9520-bbd5-439b-840f-5b88237b6f0f",
   "metadata": {},
   "source": [
    "LSTM has three gates to decide which information will flow through and which unnecessary information will be removed. In this way, gates will control the cell state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99223509-329e-4424-8d67-262dc8b8becd",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">5.2.1. Forget Gates</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baba27e-cde3-49ad-b40d-38bce055318c",
   "metadata": {},
   "source": [
    "In the first step of LSTM, forget gate decides which information should be removed from the cell state. To achieve this, the sigmoid function is used which converts values between 0 and 1 for each number in the cell state $\\small C_{t-1}$. The output value is calculated from the previous hidden state value $\\small h_{t-1}$ and new input value $\\small x_t$. Output 0 implies that it should be definitely removed from the cell state and output 1 implies it should be definitely kept in the cell state.  \n",
    "<center>![_Figure 7: The forget gate_](images/picture7.jpg)</center>  \n",
    "<center>$\\small h_{t-1}:$previous hidden state, $\\small x_t:$new input, $\\small σ:$sigmoid function, $\\small f_t:$forget gate output </center><br>\n",
    "  \n",
    "The forget gate output will be computed with  \n",
    "  \n",
    "$$f_t= σ(W_f∙(h_{t-1}+x_t) + b_f ),$$\n",
    "where $\\small W_f$ is weight and $\\small b_f$ is bias of forget gate. Later, $\\small f_t$ will be used to determine current cell state $\\small C_t$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4897ae52-4330-40bc-a3d8-f8fc6a35b435",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">5.2.2. Input Gates</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beeba91-464a-45aa-88c7-4f07b6fa6fdb",
   "metadata": {},
   "source": [
    "The input gate decides which new information will be added to the cell state. In the input gate, there are two layers, sigmoid and tanh functions. tanh layer will create new candidate values $\\small \\tilde{C_t}$  that have the potential to be added to the cell state while converting values between -1 and 1. Furthermore, similar to the case in forget gate, the input gate will choose what information is going to be stored with the help of the sigmoid function while converting values between 0 and 1. Therefore, the sigmoid function will decide which information will be added by looking at the candidate values $\\small \\tilde{C_t}$.  \n",
    "<center>![_Figure 8: The input gate_](images/picture8.jpg)</center> <center> \n",
    "$\\small h_{t-1}:$previous hidden state, $\\small x_t:$ new input, $\\small tanh:$tanh⁡function, $\\small \\tilde{C_t}:$candidate, $\\small σ:$sigmoid function, $\\small i_t:$input gate output  </center><br>\n",
    "\n",
    "Therefore, based on the information provided above, the input gate output $\\small i_t$ and the candidate value $\\small \\tilde{C_t}$ computed as  \n",
    "$$ i_t= σ(W_i∙(h_{t-1}+x_t )+ b_i ),$$\n",
    "$$\\tilde{C_t} =tanh⁡(W_C∙(h_{t-1} + x_t )+ b_C).$$  \n",
    "In the next step, with the outputs of the input and forget gates, the old cell state $\\small C_{t-1}$   will be updated into new cell state $\\small C_t$ as seen in _Figure 9_. The calculation is done by multiplying the old cell state by the forget output, which means that the ones chosen will be forgotten from the old state. Also, candidate values are multiplied by input gate output values to select from new candidate values to be added to new cell state. When these two multiplication added together, the current cell state equation obtained as  \n",
    "$$ C_t=f_t*C_{t-1}+ i_t*\\tilde{C_t}.$$\n",
    "<center>![_Figure 9: Updating the current cell state_](images/picture9.jpg)</center>  \n",
    "<center>\n",
    "$\\small f_t:$forget gate output, $\\small C_{t-1}:$ previous cell state, $\\small i_t:$input gate output, $\\small \\tilde{C_t}:$candidate, $\\small C_t:$new cell state </center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628afcc-b664-49d7-9ed2-607fd690c723",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">5.2.3. Output Gates</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9f383-eeee-4ebb-b695-33f8e5223825",
   "metadata": {},
   "source": [
    "Lastly, the output will be computed in the output gate. In the output gate, again, the sigmoid function will decide what information to get from the cell state. The output gate output calculated as \n",
    "$$O_t= σ(W_O∙(h_{t-1}+x_t )+ b_O ).$$\n",
    "The tanh function will filter the current cell state $\\small C_t$ between -1 and 1. The output will depend on current cell state $\\small C_t$ as shown in: \n",
    "$$ h_t= O_t  ×  tanh⁡(C_t ).$$\n",
    "Output of the output gate $\\small O_t$  and $\\small tanh$ of current cell state $\\small C_t$  multiplication will give the new hidden state $\\small h_t$ as seen in above. After this process, the hidden state will feed the next cell in the next step. \n",
    "<center>![_Figure 10: The output gate_](images/picture10.jpg)</center>  \n",
    "<center> $\\small h_{t-1}:$previous hidden state, $\\small x_t:$new input, $\\small σ:$sigmoid function, $\\small tanh:$tanh ⁡function, $O_t:$output gate output, $h_t:$hidden state\n",
    "</center><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd9433-af3f-4f88-9d62-54bf33acbe40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#351C75\">6. MODEL BUILDING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b7da9-7d0e-43d4-acd8-fd20d86ebe92",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">6.1. The Libraries Used</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5d27f-9cd9-4646-8e8c-4d2b6d85200f",
   "metadata": {},
   "source": [
    "The Python libraries showed in the _Table 1_, are essential to be able to use particular functions.  \n",
    "\n",
    "<style>\n",
    "table {\n",
    "  text-align:center;\n",
    "  font-family: arial, sans-serif;\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td{\n",
    "  text-align:left;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "th {\n",
    "  text-align:center;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "<table class=\"center\" >\n",
    "  <tr>\n",
    "    <th><span style=\"color:#351C75\">Libraries      </span></th>\n",
    "    <th><span style=\"color:#351C75\">Description</span></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>NumPy</b></td>\n",
    "    <td>NumPy is the essential package for scientific computing such as linear algebra.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>pandas</b></td>\n",
    "    <td>Pandas is an open-source data analysis and manipulation tool built on the Python programming language.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>math</b></td>\n",
    "    <td>For mathematical function, math library is used.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>sklearn</b></td>\n",
    "    <td>Sklearn library is essential for machine learning applications and statistical modeling in term of tools for classification and regression.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>tensorflow</b></td>\n",
    "    <td>TensorFlow is an open-source library which is used mainly for deep learning applications.</td>\n",
    "  </tr>\n",
    "    <td><b>keras</b></td>\n",
    "    <td>Keras which runs on top of the TensorFlow is used for evaluating deep learning models such as artificial neural networks.</td>\n",
    "  <tr>\n",
    "    <td><b>matplotlib</b></td>\n",
    "    <td>Matplotlib is useful library for data visualization and graphical plotting.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p><center> Table 1: Python libraries used. </p></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffad1d3-3832-4bc0-85ac-c457f394fb99",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">6.2. The Dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879d0fb-f44a-4495-9d2f-e50606c29f4d",
   "metadata": {},
   "source": [
    "The dataset includes several countries and their export values as time series. The dataset has been created with 44 country pairs and a total of 12 countries. Additionally, some factors that may be related to export values such as distance between country pairs, GDP value of each country, and more, were collected. For this project, 20 years from 2000 to 2019 are chosen to work with.\n",
    "\n",
    "The European Free Trade Association (EFTA) is an organization run by four members, Iceland, Liechtenstein, Norway, and Switzerland to promote free trade and economic integration for the benefit of its members. \n",
    "\n",
    "A Free Trade Agreement (FTA) is a type of trade agreement between countries to lower trade barriers. The EFTA countries intended to contribute to the growth of international trade. For that reason, in 1991, FTA has been signed between the Republic of Turkey and EFTA States.  \n",
    "\n",
    "In this project, the export values of EFTA countries and Turkey have been considered and taken from the World Bank which gave in US$ thousand. Unfortunately, Liechtenstein was not included since there were no data about its export values on [World Integrated Trade.](https://wits.worldbank.org/CountryProfile/en/Country/TUR/StartYear/2000/EndYear/2019/TradeFlow/Export/Partner/BY-COUNTRY/Indicator/XPRT-TRD-VL)  \n",
    "\n",
    "Norway, Switzerland, Iceland, and Turkey were taken as exporting countries. The export values between exporting countries and several importing countries were analyzed. The import countries were taken as China, Netherlands, United States of America, United Kingdom, Spain, Italy, Germany, France, Norway, Switzerland, Iceland, and Turkey.\n",
    "\n",
    "Developing economies can benefit from international trade more. Considering that, there is a positive correlation between trade and economic size. Thus, the gross domestic product (GDP) and the gross domestic product per capita (GDPPC) data in US$ for individual countries were taken from [The World Bank’s database.](https://databank.worldbank.org/indicator/NY.GDP.MKTP.CD/1ff4a498/Popular-Indicators)  \n",
    "Due to transportation costs, trade is more reasonable when distances are shorter. Therefore, the distance between capital cities of countries has been taken in kilometers from [European Union website](https://erasmus-plus.ec.europa.eu/resources-and-tools/distance-calculator), and after, an excel file has been created to work on.\n",
    "\n",
    "After taking data from several resources, the data has been converted as seen in _Table 2_ with data wrangling in Python.  \n",
    "\n",
    "\n",
    "<style>\n",
    "table {\n",
    "  text-align:center;\n",
    "  font-family: arial, sans-serif;\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td{\n",
    "  text-align:left;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "th {\n",
    "  text-align:center;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "<table class=\"center\" >\n",
    "  <tr>\n",
    "    <th><span style=\"color:#351C75\">Column Name     </th>\n",
    "    <th><span style=\"color:#351C75\">Description</th>\n",
    "    <th><span style=\"color:#351C75\">Type</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Export</td>\n",
    "    <td>The exporting country $\\small i$</td>\n",
    "    <td>Categorical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Import</td>\n",
    "    <td>The importing country $\\small j$</td>\n",
    "    <td>Categorical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Year</td>\n",
    "    <td>Year $\\small t$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Export_Value</td>\n",
    "    <td>The export of country $\\small i$ to country $\\small j$ in year $\\small t$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Export_Value_(t-1)</td>\n",
    "    <td>The export of country $\\small i$ to country $\\small j$ in year $\\small t-1$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>GDP_i(t-1)</td>\n",
    "    <td>The Gross Domestic Product of country $\\small i$ in year $\\small t-1$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>GDP_j(t-1)</td>\n",
    "    <td>The Gross Domestic Product of country $\\small i$ in year $\\small t-1$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td><b>GDPPC_i(t-1)</td>\n",
    "    <td>The Gross Domestic Product of country $\\small j$ in year $\\small t-1$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td><b>GDPPC_j(t-1)</td>\n",
    "    <td>The per capita Gross Domestic Product of country $\\small j$ in year $\\small t-1$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td><b>D_ij</td>\n",
    "    <td>The distance in km between the capital cities of country $\\small i$ and $\\small j$</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>FTA_1</td>\n",
    "    <td>Dummy variable which takes value of 1 if both countries were members of EFTA-Turkey FTA</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td><b>FTA_2</td>\n",
    "    <td>Dummy variable which takes value of 1 if the exporting country $\\small i$ was a member of EFTA-Turkey FTA but the importing country $\\small j$ did not belong to EFTA-Turkey FTA</td>\n",
    "    <td>Numerical</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p><center> Table 2: Columns and their description after tidying dataset. </p></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abaa54-bf2b-4c20-b5ab-9db5556d73a1",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">6.3. Data Wrangling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d811e2-95f0-4ef1-b218-b87de61168f6",
   "metadata": {},
   "source": [
    "In order to obtain the data as in _Table 2_, data wrangling should be done. In this project, data \n",
    "wrangling is made with Python. \n",
    "\n",
    "Throughout this section, the data frames are displayed using the head function for a better understanding of the changes. The head function shows the data frame's first five rows.\n",
    "\n",
    "Firstly, libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a33a06-fbce-4032-948f-0e1cbe3a0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbd97b-c1c9-4647-ab54-fc64153282dd",
   "metadata": {},
   "source": [
    "As mentioned before, the data sets which cotain each EFTA countries' export values over the years is taken from [here](https://wits.worldbank.org/CountryProfile/en/Country/TUR/StartYear/2000/EndYear/2018/TradeFlow/Export/Partner/BY-COUNTRY/Indicator/XPRT-TRD-VL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c8fb96-0251-4ce7-bbe4-e27ad8b384f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Trade Flow</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.508</td>\n",
       "      <td>8.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.546</td>\n",
       "      <td>551.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.009069</td>\n",
       "      <td>1.474556</td>\n",
       "      <td>97.63208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118</td>\n",
       "      <td>327.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888</td>\n",
       "      <td>28.992494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.980</td>\n",
       "      <td>4.673</td>\n",
       "      <td>377.096</td>\n",
       "      <td>622.460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.36868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name Trade Flow   Product Group  \\\n",
       "0       Iceland     Afghanistan     Export    All Products   \n",
       "1       Iceland         Albania     Export    All Products   \n",
       "2       Iceland         Algeria     Export    All Products   \n",
       "3       Iceland  American Samoa     Export    All Products   \n",
       "4       Iceland         Andorra     Export    All Products   \n",
       "\n",
       "               Indicator  1999   2000    2001  2002  2003  ...    2010  \\\n",
       "0  Export (US$ Thousand)   NaN    NaN     NaN   NaN   NaN  ...  12.488   \n",
       "1  Export (US$ Thousand)   NaN    NaN     NaN   NaN   NaN  ...   6.508   \n",
       "2  Export (US$ Thousand)   NaN  0.118  327.77   NaN   NaN  ...     NaN   \n",
       "3  Export (US$ Thousand)   NaN    NaN     NaN   NaN   NaN  ...   2.321   \n",
       "4  Export (US$ Thousand)   NaN    NaN     NaN   NaN   NaN  ...     NaN   \n",
       "\n",
       "      2011   2012     2013     2014    2015   2016       2017      2018  \\\n",
       "0      NaN    NaN      NaN      NaN     NaN  0.047        NaN       NaN   \n",
       "1    8.658    NaN      NaN    1.546  551.29    NaN  37.009069  1.474556   \n",
       "2      NaN    NaN      NaN      NaN     NaN  0.888  28.992494       NaN   \n",
       "3      NaN    NaN      NaN      NaN     NaN    NaN        NaN       NaN   \n",
       "4  143.980  4.673  377.096  622.460     NaN    NaN        NaN       NaN   \n",
       "\n",
       "       2019  \n",
       "0       NaN  \n",
       "1  97.63208  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4  93.36868  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceland_export = pd.read_excel(\"data/iceland_exp.xlsx\", sheet_name='Partner-Timeseries')\n",
    "iceland_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93091f1f-2bc8-49d1-82b4-e177a6225ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Trade Flow</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>668.770</td>\n",
       "      <td>1030.697</td>\n",
       "      <td>70.238</td>\n",
       "      <td>1259.632</td>\n",
       "      <td>806.352</td>\n",
       "      <td>...</td>\n",
       "      <td>5274.291</td>\n",
       "      <td>10802.994</td>\n",
       "      <td>12235.926</td>\n",
       "      <td>9672.623</td>\n",
       "      <td>7938.746</td>\n",
       "      <td>7375.227</td>\n",
       "      <td>3783.544</td>\n",
       "      <td>2976.761784</td>\n",
       "      <td>2648.381385</td>\n",
       "      <td>4483.761721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>4470.970</td>\n",
       "      <td>5374.934</td>\n",
       "      <td>6388.568</td>\n",
       "      <td>14023.823</td>\n",
       "      <td>13401.324</td>\n",
       "      <td>...</td>\n",
       "      <td>32861.966</td>\n",
       "      <td>40591.127</td>\n",
       "      <td>33079.626</td>\n",
       "      <td>34440.891</td>\n",
       "      <td>32012.522</td>\n",
       "      <td>33727.996</td>\n",
       "      <td>37925.220</td>\n",
       "      <td>41551.097724</td>\n",
       "      <td>50835.760544</td>\n",
       "      <td>54660.835135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>80953.832</td>\n",
       "      <td>76352.109</td>\n",
       "      <td>85082.564</td>\n",
       "      <td>91694.656</td>\n",
       "      <td>105476.061</td>\n",
       "      <td>...</td>\n",
       "      <td>479494.968</td>\n",
       "      <td>525203.022</td>\n",
       "      <td>423156.936</td>\n",
       "      <td>456145.485</td>\n",
       "      <td>530048.207</td>\n",
       "      <td>378307.150</td>\n",
       "      <td>338564.182</td>\n",
       "      <td>361437.281185</td>\n",
       "      <td>411050.211499</td>\n",
       "      <td>346559.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>82.316</td>\n",
       "      <td>19.774</td>\n",
       "      <td>759.053</td>\n",
       "      <td>1.726</td>\n",
       "      <td>116.203</td>\n",
       "      <td>1907.902</td>\n",
       "      <td>27.646</td>\n",
       "      <td>33.029329</td>\n",
       "      <td>48.050476</td>\n",
       "      <td>6.860180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>8065.533</td>\n",
       "      <td>8134.753</td>\n",
       "      <td>6931.478</td>\n",
       "      <td>6894.058</td>\n",
       "      <td>7768.624</td>\n",
       "      <td>...</td>\n",
       "      <td>7862.934</td>\n",
       "      <td>6570.842</td>\n",
       "      <td>5621.689</td>\n",
       "      <td>14513.697</td>\n",
       "      <td>6228.208</td>\n",
       "      <td>5680.020</td>\n",
       "      <td>6676.195</td>\n",
       "      <td>9516.519122</td>\n",
       "      <td>6548.998445</td>\n",
       "      <td>3410.361410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name Trade Flow   Product Group  \\\n",
       "0   Switzerland     Afghanistan     Export    All Products   \n",
       "1   Switzerland         Albania     Export    All Products   \n",
       "2   Switzerland         Algeria     Export    All Products   \n",
       "3   Switzerland  American Samoa     Export    All Products   \n",
       "4   Switzerland         Andorra     Export    All Products   \n",
       "\n",
       "               Indicator       1999       2000       2001       2002  \\\n",
       "0  Export (US$ Thousand)    668.770   1030.697     70.238   1259.632   \n",
       "1  Export (US$ Thousand)   4470.970   5374.934   6388.568  14023.823   \n",
       "2  Export (US$ Thousand)  80953.832  76352.109  85082.564  91694.656   \n",
       "3  Export (US$ Thousand)        NaN        NaN        NaN        NaN   \n",
       "4  Export (US$ Thousand)   8065.533   8134.753   6931.478   6894.058   \n",
       "\n",
       "         2003  ...        2010        2011        2012        2013  \\\n",
       "0     806.352  ...    5274.291   10802.994   12235.926    9672.623   \n",
       "1   13401.324  ...   32861.966   40591.127   33079.626   34440.891   \n",
       "2  105476.061  ...  479494.968  525203.022  423156.936  456145.485   \n",
       "3         NaN  ...      82.316      19.774     759.053       1.726   \n",
       "4    7768.624  ...    7862.934    6570.842    5621.689   14513.697   \n",
       "\n",
       "         2014        2015        2016           2017           2018  \\\n",
       "0    7938.746    7375.227    3783.544    2976.761784    2648.381385   \n",
       "1   32012.522   33727.996   37925.220   41551.097724   50835.760544   \n",
       "2  530048.207  378307.150  338564.182  361437.281185  411050.211499   \n",
       "3     116.203    1907.902      27.646      33.029329      48.050476   \n",
       "4    6228.208    5680.020    6676.195    9516.519122    6548.998445   \n",
       "\n",
       "            2019  \n",
       "0    4483.761721  \n",
       "1   54660.835135  \n",
       "2  346559.000132  \n",
       "3       6.860180  \n",
       "4    3410.361410  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switzerland_export = pd.read_excel(\"data/switzerland_exp.xlsx\", sheet_name='Partner-Timeseries')\n",
    "switzerland_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8632181b-669b-4fb4-b3d1-d323974ac25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Trade Flow</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>669.546</td>\n",
       "      <td>6.462</td>\n",
       "      <td>839.591</td>\n",
       "      <td>45.695</td>\n",
       "      <td>2691.172</td>\n",
       "      <td>...</td>\n",
       "      <td>3078.104</td>\n",
       "      <td>2600.718</td>\n",
       "      <td>3551.239</td>\n",
       "      <td>5932.199</td>\n",
       "      <td>3126.715</td>\n",
       "      <td>2374.386477</td>\n",
       "      <td>1311.651</td>\n",
       "      <td>2260.749492</td>\n",
       "      <td>1628.383320</td>\n",
       "      <td>3184.828916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>3540.155</td>\n",
       "      <td>5166.692</td>\n",
       "      <td>4287.898</td>\n",
       "      <td>254.031</td>\n",
       "      <td>177.315</td>\n",
       "      <td>...</td>\n",
       "      <td>1608.627</td>\n",
       "      <td>1279.707</td>\n",
       "      <td>905.432</td>\n",
       "      <td>1562.152</td>\n",
       "      <td>1665.014</td>\n",
       "      <td>1602.095556</td>\n",
       "      <td>2515.775</td>\n",
       "      <td>1793.066618</td>\n",
       "      <td>2985.267980</td>\n",
       "      <td>4652.082076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>5881.129</td>\n",
       "      <td>7283.935</td>\n",
       "      <td>4611.381</td>\n",
       "      <td>6305.214</td>\n",
       "      <td>3343.711</td>\n",
       "      <td>...</td>\n",
       "      <td>11291.508</td>\n",
       "      <td>148812.670</td>\n",
       "      <td>285439.717</td>\n",
       "      <td>42674.529</td>\n",
       "      <td>104205.985</td>\n",
       "      <td>51579.762487</td>\n",
       "      <td>26406.936</td>\n",
       "      <td>55542.880847</td>\n",
       "      <td>67119.192832</td>\n",
       "      <td>63202.683648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.020</td>\n",
       "      <td>2.256</td>\n",
       "      <td>1.648</td>\n",
       "      <td>...</td>\n",
       "      <td>62.128</td>\n",
       "      <td>26.821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.688757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.107250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>193.397</td>\n",
       "      <td>50.907</td>\n",
       "      <td>70.653</td>\n",
       "      <td>16.552</td>\n",
       "      <td>192.449</td>\n",
       "      <td>...</td>\n",
       "      <td>11.757</td>\n",
       "      <td>2.035</td>\n",
       "      <td>230.913</td>\n",
       "      <td>28.965</td>\n",
       "      <td>47.522</td>\n",
       "      <td>210.076745</td>\n",
       "      <td>18.981</td>\n",
       "      <td>46.978205</td>\n",
       "      <td>115.654673</td>\n",
       "      <td>73.440039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name Trade Flow   Product Group  \\\n",
       "0        Norway     Afghanistan     Export    All Products   \n",
       "1        Norway         Albania     Export    All Products   \n",
       "2        Norway         Algeria     Export    All Products   \n",
       "3        Norway  American Samoa     Export    All Products   \n",
       "4        Norway         Andorra     Export    All Products   \n",
       "\n",
       "               Indicator      1999      2000      2001      2002      2003  \\\n",
       "0  Export (US$ Thousand)   669.546     6.462   839.591    45.695  2691.172   \n",
       "1  Export (US$ Thousand)  3540.155  5166.692  4287.898   254.031   177.315   \n",
       "2  Export (US$ Thousand)  5881.129  7283.935  4611.381  6305.214  3343.711   \n",
       "3  Export (US$ Thousand)       NaN       NaN     2.020     2.256     1.648   \n",
       "4  Export (US$ Thousand)   193.397    50.907    70.653    16.552   192.449   \n",
       "\n",
       "   ...       2010        2011        2012       2013        2014  \\\n",
       "0  ...   3078.104    2600.718    3551.239   5932.199    3126.715   \n",
       "1  ...   1608.627    1279.707     905.432   1562.152    1665.014   \n",
       "2  ...  11291.508  148812.670  285439.717  42674.529  104205.985   \n",
       "3  ...     62.128      26.821         NaN    250.929         NaN   \n",
       "4  ...     11.757       2.035     230.913     28.965      47.522   \n",
       "\n",
       "           2015       2016          2017          2018          2019  \n",
       "0   2374.386477   1311.651   2260.749492   1628.383320   3184.828916  \n",
       "1   1602.095556   2515.775   1793.066618   2985.267980   4652.082076  \n",
       "2  51579.762487  26406.936  55542.880847  67119.192832  63202.683648  \n",
       "3           NaN        NaN      3.688757           NaN      5.107250  \n",
       "4    210.076745     18.981     46.978205    115.654673     73.440039  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norway_export = pd.read_excel(\"data/norway_exp.xlsx\", sheet_name='Partner-Timeseries')\n",
    "norway_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e639258-a527-4968-8c0a-4e92c3cf4782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Trade Flow</th>\n",
       "      <th>Product Group</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>667.240</td>\n",
       "      <td>8053.165</td>\n",
       "      <td>6982.852</td>\n",
       "      <td>20231.718</td>\n",
       "      <td>36488.933</td>\n",
       "      <td>...</td>\n",
       "      <td>259790.540</td>\n",
       "      <td>275969.018</td>\n",
       "      <td>289915.446</td>\n",
       "      <td>228231.291</td>\n",
       "      <td>186184.915</td>\n",
       "      <td>161634.386</td>\n",
       "      <td>145590.972</td>\n",
       "      <td>172300.022</td>\n",
       "      <td>145637.138</td>\n",
       "      <td>156474.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>65607.192</td>\n",
       "      <td>61271.753</td>\n",
       "      <td>73204.959</td>\n",
       "      <td>78789.263</td>\n",
       "      <td>114426.136</td>\n",
       "      <td>...</td>\n",
       "      <td>241066.433</td>\n",
       "      <td>270630.397</td>\n",
       "      <td>255949.988</td>\n",
       "      <td>266543.599</td>\n",
       "      <td>318540.934</td>\n",
       "      <td>287395.257</td>\n",
       "      <td>304605.826</td>\n",
       "      <td>387115.810</td>\n",
       "      <td>408970.359</td>\n",
       "      <td>487239.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>407613.344</td>\n",
       "      <td>376302.119</td>\n",
       "      <td>421963.836</td>\n",
       "      <td>510836.703</td>\n",
       "      <td>573001.756</td>\n",
       "      <td>...</td>\n",
       "      <td>1504590.140</td>\n",
       "      <td>1470547.381</td>\n",
       "      <td>1813036.624</td>\n",
       "      <td>2002688.972</td>\n",
       "      <td>2078889.041</td>\n",
       "      <td>1825987.699</td>\n",
       "      <td>1736370.650</td>\n",
       "      <td>1712901.470</td>\n",
       "      <td>2031739.676</td>\n",
       "      <td>2016394.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.213</td>\n",
       "      <td>653.501</td>\n",
       "      <td>...</td>\n",
       "      <td>64.099</td>\n",
       "      <td>52.866</td>\n",
       "      <td>190.229</td>\n",
       "      <td>222.228</td>\n",
       "      <td>145.504</td>\n",
       "      <td>299.278</td>\n",
       "      <td>1090.786</td>\n",
       "      <td>181.042</td>\n",
       "      <td>98.968</td>\n",
       "      <td>113.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Export</td>\n",
       "      <td>All Products</td>\n",
       "      <td>Export (US$ Thousand)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.443</td>\n",
       "      <td>6.783</td>\n",
       "      <td>167.419</td>\n",
       "      <td>...</td>\n",
       "      <td>332.877</td>\n",
       "      <td>477.100</td>\n",
       "      <td>350.263</td>\n",
       "      <td>408.229</td>\n",
       "      <td>555.619</td>\n",
       "      <td>939.558</td>\n",
       "      <td>369.595</td>\n",
       "      <td>268.903</td>\n",
       "      <td>552.414</td>\n",
       "      <td>344.606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name Trade Flow   Product Group  \\\n",
       "0        Turkey     Afghanistan     Export    All Products   \n",
       "1        Turkey         Albania     Export    All Products   \n",
       "2        Turkey         Algeria     Export    All Products   \n",
       "3        Turkey  American Samoa     Export    All Products   \n",
       "4        Turkey         Andorra     Export    All Products   \n",
       "\n",
       "               Indicator        1999        2000        2001        2002  \\\n",
       "0  Export (US$ Thousand)     667.240    8053.165    6982.852   20231.718   \n",
       "1  Export (US$ Thousand)   65607.192   61271.753   73204.959   78789.263   \n",
       "2  Export (US$ Thousand)  407613.344  376302.119  421963.836  510836.703   \n",
       "3  Export (US$ Thousand)         NaN         NaN         NaN       5.213   \n",
       "4  Export (US$ Thousand)         NaN         NaN      59.443       6.783   \n",
       "\n",
       "         2003  ...         2010         2011         2012         2013  \\\n",
       "0   36488.933  ...   259790.540   275969.018   289915.446   228231.291   \n",
       "1  114426.136  ...   241066.433   270630.397   255949.988   266543.599   \n",
       "2  573001.756  ...  1504590.140  1470547.381  1813036.624  2002688.972   \n",
       "3     653.501  ...       64.099       52.866      190.229      222.228   \n",
       "4     167.419  ...      332.877      477.100      350.263      408.229   \n",
       "\n",
       "          2014         2015         2016         2017         2018  \\\n",
       "0   186184.915   161634.386   145590.972   172300.022   145637.138   \n",
       "1   318540.934   287395.257   304605.826   387115.810   408970.359   \n",
       "2  2078889.041  1825987.699  1736370.650  1712901.470  2031739.676   \n",
       "3      145.504      299.278     1090.786      181.042       98.968   \n",
       "4      555.619      939.558      369.595      268.903      552.414   \n",
       "\n",
       "          2019  \n",
       "0   156474.516  \n",
       "1   487239.263  \n",
       "2  2016394.568  \n",
       "3      113.697  \n",
       "4      344.606  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey_export = pd.read_excel(\"data/turkey_exp.xlsx\", sheet_name='Partner-Timeseries')\n",
    "turkey_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1811aa-0b02-4537-82a8-ffee4e4cdd2b",
   "metadata": {},
   "source": [
    "In the data frames, year columns should be converted into rows. Therefore, to unpivot the data frames, the melt function is used. In this way, each year will become rows and the export value of the country in that year will be in the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dee1791-4ffa-4f86-9ec7-be0d6589c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_export = ['1999','2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008',\n",
    "                '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5554f131-14ea-46dc-a2a0-ba6a697bfe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1999</td>\n",
       "      <td>667.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Albania</td>\n",
       "      <td>1999</td>\n",
       "      <td>65607.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1999</td>\n",
       "      <td>407613.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name  Year  Export_Value\n",
       "0        Turkey     Afghanistan  1999       667.240\n",
       "1        Turkey         Albania  1999     65607.192\n",
       "2        Turkey         Algeria  1999    407613.344\n",
       "3        Turkey  American Samoa  1999           NaN\n",
       "4        Turkey         Andorra  1999           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey_export = turkey_export.melt(id_vars=['Reporter Name','Partner Name'], value_vars=years_export,\n",
    "              var_name='Year', value_name ='Export_Value')\n",
    "turkey_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428a0f0f-4e3d-4f0e-a299-7c0a9b1a23d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1999</td>\n",
       "      <td>669.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Albania</td>\n",
       "      <td>1999</td>\n",
       "      <td>3540.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1999</td>\n",
       "      <td>5881.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>1999</td>\n",
       "      <td>193.397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name  Year  Export_Value\n",
       "0        Norway     Afghanistan  1999       669.546\n",
       "1        Norway         Albania  1999      3540.155\n",
       "2        Norway         Algeria  1999      5881.129\n",
       "3        Norway  American Samoa  1999           NaN\n",
       "4        Norway         Andorra  1999       193.397"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norway_export = norway_export.melt(id_vars=['Reporter Name','Partner Name'], value_vars=years_export,\n",
    "              var_name='Year', value_name='Export_Value')\n",
    "norway_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35e08ce-2e06-47d8-88a1-67fd5e8f98b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Albania</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name  Year  Export_Value\n",
       "0       Iceland     Afghanistan  1999           NaN\n",
       "1       Iceland         Albania  1999           NaN\n",
       "2       Iceland         Algeria  1999           NaN\n",
       "3       Iceland  American Samoa  1999           NaN\n",
       "4       Iceland         Andorra  1999           NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceland_export = iceland_export.melt(id_vars=['Reporter Name','Partner Name'], value_vars=years_export,\n",
    "              var_name='Year', value_name='Export_Value')\n",
    "iceland_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dba6a5d-0e05-4dc6-a694-7299d4d6db7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporter Name</th>\n",
       "      <th>Partner Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1999</td>\n",
       "      <td>668.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Albania</td>\n",
       "      <td>1999</td>\n",
       "      <td>4470.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1999</td>\n",
       "      <td>80953.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>1999</td>\n",
       "      <td>8065.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reporter Name    Partner Name  Year  Export_Value\n",
       "0   Switzerland     Afghanistan  1999       668.770\n",
       "1   Switzerland         Albania  1999      4470.970\n",
       "2   Switzerland         Algeria  1999     80953.832\n",
       "3   Switzerland  American Samoa  1999           NaN\n",
       "4   Switzerland         Andorra  1999      8065.533"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switzerland_export = switzerland_export.melt(id_vars=['Reporter Name','Partner Name'], value_vars=years_export,\n",
    "              var_name='Year', value_name='Export_Value')\n",
    "switzerland_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bccecc-2b78-4235-8728-daccb414cbd5",
   "metadata": {},
   "source": [
    "Firstly, the names of columns have been renamed. In each country’s data frame, there are data for all countries they import to. Therefore, for each data frame, the decided importing countries are filtered. And since, the exporting countries are also importing countries, for each data frame a new importing country list should have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01d2ccc-d37d-49c2-888a-9d196ea45083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>36637.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>France</td>\n",
       "      <td>1999</td>\n",
       "      <td>1573188.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1999</td>\n",
       "      <td>5474533.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1999</td>\n",
       "      <td>2333.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1999</td>\n",
       "      <td>1682516.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Export   Import  Year  Export_Value\n",
       "44   Turkey    China  1999     36637.176\n",
       "78   Turkey   France  1999   1573188.736\n",
       "84   Turkey  Germany  1999   5474533.888\n",
       "101  Turkey  Iceland  1999      2333.333\n",
       "108  Turkey    Italy  1999   1682516.992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey_export.rename(columns = {'Reporter Name' : 'Export', 'Partner Name' : 'Import'}, inplace = True)\n",
    "turkey_exp_country = ['China', 'France', 'Germany', 'Iceland', 'Italy', 'Netherlands',\n",
    "                     'Norway', 'Spain', 'Switzerland', 'United Kingdom', 'United States']\n",
    "turkey_export = turkey_export.loc[turkey_export['Import'].isin(turkey_exp_country)]\n",
    "turkey_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06329e53-c939-49e5-a67f-591bcbb39f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Norway</td>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>512144.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Norway</td>\n",
       "      <td>France</td>\n",
       "      <td>1999</td>\n",
       "      <td>3792969.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1999</td>\n",
       "      <td>4565479.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1999</td>\n",
       "      <td>249823.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1999</td>\n",
       "      <td>1000314.880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Export   Import  Year  Export_Value\n",
       "42   Norway    China  1999    512144.640\n",
       "75   Norway   France  1999   3792969.728\n",
       "80   Norway  Germany  1999   4565479.936\n",
       "96   Norway  Iceland  1999    249823.456\n",
       "103  Norway    Italy  1999   1000314.880"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norway_export.rename(columns = {'Reporter Name' : 'Export', 'Partner Name' : 'Import'}, inplace = True)\n",
    "norway_exp_country = ['China', 'France', 'Germany', 'Iceland', 'Italy', 'Netherlands',\n",
    "       'Spain', 'Switzerland', 'Turkey', 'United Kingdom', 'United States']\n",
    "norway_export = norway_export.loc[norway_export['Import'].isin(norway_exp_country)]\n",
    "norway_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657b3880-e1fa-4ba0-9b48-a71333cd4cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.584765e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>France</td>\n",
       "      <td>1999</td>\n",
       "      <td>7.415515e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.811240e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.708245e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.385132e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Export   Import  Year  Export_Value\n",
       "45   Switzerland    China  1999  6.584765e+05\n",
       "79   Switzerland   France  1999  7.415515e+06\n",
       "84   Switzerland  Germany  1999  1.811240e+07\n",
       "101  Switzerland  Iceland  1999  1.708245e+04\n",
       "108  Switzerland    Italy  1999  6.385132e+06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switzerland_export.rename(columns = {'Reporter Name' : 'Export', 'Partner Name' : 'Import'}, inplace = True)\n",
    "switzerland_exp_country = ['China', 'France', 'Germany', 'Iceland', 'Italy', 'Netherlands',\n",
    "       'Norway', 'Spain', 'Turkey', 'United Kingdom', 'United States']\n",
    "switzerland_export=switzerland_export.loc[switzerland_export['Import'].isin(switzerland_exp_country)]\n",
    "switzerland_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536661cc-9369-49cd-9e14-acbb3fae2cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>5022.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>France</td>\n",
       "      <td>1999</td>\n",
       "      <td>104187.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1999</td>\n",
       "      <td>262963.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1999</td>\n",
       "      <td>34470.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1999</td>\n",
       "      <td>120782.848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Export       Import  Year  Export_Value\n",
       "39   Iceland        China  1999      5022.337\n",
       "69   Iceland       France  1999    104187.632\n",
       "74   Iceland      Germany  1999    262963.856\n",
       "96   Iceland        Italy  1999     34470.260\n",
       "132  Iceland  Netherlands  1999    120782.848"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iceland_export.rename(columns = {'Reporter Name' : 'Export', 'Partner Name' : 'Import'}, inplace = True)\n",
    "iceland_exp_country = ['China', 'France', 'Germany', 'Italy', 'Netherlands',\n",
    "       'Norway', 'Spain', 'Switzerland', 'Turkey', 'United Kingdom', 'United States']\n",
    "iceland_export=iceland_export.loc[iceland_export['Import'].isin(iceland_exp_country)]\n",
    "iceland_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58da79-7ca8-43b0-9aca-e7078f5ffcb3",
   "metadata": {},
   "source": [
    "4 data sets containing export data of Turkey, Norway, Switzerland, and Iceland, respectively, are concatenated using the concat function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432b8e8b-a833-4b42-afaa-d09cf3df9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_all = pd.concat([turkey_export, norway_export, switzerland_export,\n",
    "                             iceland_export]).reset_index().drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead415b7-17ba-4b69-9d1e-fb1a2518480b",
   "metadata": {},
   "source": [
    "Object columns, \"Year\" and \"Export_Value\", is converted to numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2390b55-6b1a-4373-b686-ab717fd2d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_all[\"Year\"] = pd.to_numeric(export_data_all[\"Year\"])\n",
    "export_data_all[\"Export_Value\"] = pd.to_numeric(export_data_all[\"Export_Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0c68a-9e9e-4d05-80ab-8fd8873c9926",
   "metadata": {},
   "source": [
    "The data set is separated into two as export_data_1999 and export_data for specifically the year 1999 and the rest, respectively. Since 1999 year will be used only for the previous year's export value, the main data frame will include 2000-2019 which is called export_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a267a8f-7bb9-4680-8694-f501e7539c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_1999 = export_data_all[export_data_all['Year'] == 1999]\n",
    "export_data = export_data_all[export_data_all['Year'] != 1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8f6ae-7af5-43a3-ad13-9f68b1a4fd9f",
   "metadata": {},
   "source": [
    "After export_data is created, data set that contains GDP and GDPPC values of each country over the years is imported. Values after the 24th row are not taken, since they are nonmeaningful rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e0a7d1b-7560-457e-bc88-d05ec7cd50f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>1999 [YR1999]</th>\n",
       "      <th>2000 [YR2000]</th>\n",
       "      <th>2001 [YR2001]</th>\n",
       "      <th>2002 [YR2002]</th>\n",
       "      <th>2003 [YR2003]</th>\n",
       "      <th>2004 [YR2004]</th>\n",
       "      <th>...</th>\n",
       "      <th>2010 [YR2010]</th>\n",
       "      <th>2011 [YR2011]</th>\n",
       "      <th>2012 [YR2012]</th>\n",
       "      <th>2013 [YR2013]</th>\n",
       "      <th>2014 [YR2014]</th>\n",
       "      <th>2015 [YR2015]</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "      <th>2017 [YR2017]</th>\n",
       "      <th>2018 [YR2018]</th>\n",
       "      <th>2019 [YR2019]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>1.362249e+12</td>\n",
       "      <td>1.376465e+12</td>\n",
       "      <td>1.494287e+12</td>\n",
       "      <td>1.840481e+12</td>\n",
       "      <td>2.115742e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642610e+12</td>\n",
       "      <td>2.861408e+12</td>\n",
       "      <td>2.683825e+12</td>\n",
       "      <td>2.811078e+12</td>\n",
       "      <td>2.852166e+12</td>\n",
       "      <td>2.438208e+12</td>\n",
       "      <td>2.471286e+12</td>\n",
       "      <td>2.588741e+12</td>\n",
       "      <td>2.789594e+12</td>\n",
       "      <td>2.728870e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>TUR</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>2.743030e+11</td>\n",
       "      <td>2.017511e+11</td>\n",
       "      <td>2.402532e+11</td>\n",
       "      <td>3.145924e+11</td>\n",
       "      <td>4.088760e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>7.769926e+11</td>\n",
       "      <td>8.387628e+11</td>\n",
       "      <td>8.805564e+11</td>\n",
       "      <td>9.577830e+11</td>\n",
       "      <td>9.389526e+11</td>\n",
       "      <td>8.643167e+11</td>\n",
       "      <td>8.696930e+11</td>\n",
       "      <td>8.589963e+11</td>\n",
       "      <td>7.784719e+11</td>\n",
       "      <td>7.610044e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>9.630664e+12</td>\n",
       "      <td>1.025235e+13</td>\n",
       "      <td>1.058182e+13</td>\n",
       "      <td>1.093642e+13</td>\n",
       "      <td>1.145824e+13</td>\n",
       "      <td>1.221373e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499205e+13</td>\n",
       "      <td>1.554258e+13</td>\n",
       "      <td>1.619701e+13</td>\n",
       "      <td>1.678485e+13</td>\n",
       "      <td>1.752716e+13</td>\n",
       "      <td>1.823830e+13</td>\n",
       "      <td>1.874508e+13</td>\n",
       "      <td>1.954298e+13</td>\n",
       "      <td>2.061186e+13</td>\n",
       "      <td>2.143322e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBR</td>\n",
       "      <td>1.685763e+12</td>\n",
       "      <td>1.662127e+12</td>\n",
       "      <td>1.643908e+12</td>\n",
       "      <td>1.784077e+12</td>\n",
       "      <td>2.057094e+12</td>\n",
       "      <td>2.421814e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.491110e+12</td>\n",
       "      <td>2.674891e+12</td>\n",
       "      <td>2.719158e+12</td>\n",
       "      <td>2.803291e+12</td>\n",
       "      <td>3.087166e+12</td>\n",
       "      <td>2.956574e+12</td>\n",
       "      <td>2.722852e+12</td>\n",
       "      <td>2.699017e+12</td>\n",
       "      <td>2.900791e+12</td>\n",
       "      <td>2.878674e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>Italy</td>\n",
       "      <td>ITA</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>1.143830e+12</td>\n",
       "      <td>1.167013e+12</td>\n",
       "      <td>1.270712e+12</td>\n",
       "      <td>1.574146e+12</td>\n",
       "      <td>1.803227e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.134018e+12</td>\n",
       "      <td>2.291991e+12</td>\n",
       "      <td>2.087077e+12</td>\n",
       "      <td>2.141315e+12</td>\n",
       "      <td>2.159134e+12</td>\n",
       "      <td>1.835899e+12</td>\n",
       "      <td>1.875797e+12</td>\n",
       "      <td>1.956950e+12</td>\n",
       "      <td>2.090911e+12</td>\n",
       "      <td>2.009384e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Series Name     Series Code    Country Name Country Code  \\\n",
       "0  GDP (current US$)  NY.GDP.MKTP.CD          France          FRA   \n",
       "1  GDP (current US$)  NY.GDP.MKTP.CD          Turkey          TUR   \n",
       "2  GDP (current US$)  NY.GDP.MKTP.CD   United States          USA   \n",
       "3  GDP (current US$)  NY.GDP.MKTP.CD  United Kingdom          GBR   \n",
       "4  GDP (current US$)  NY.GDP.MKTP.CD           Italy          ITA   \n",
       "\n",
       "   1999 [YR1999]  2000 [YR2000]  2001 [YR2001]  2002 [YR2002]  2003 [YR2003]  \\\n",
       "0   1.492648e+12   1.362249e+12   1.376465e+12   1.494287e+12   1.840481e+12   \n",
       "1   2.563855e+11   2.743030e+11   2.017511e+11   2.402532e+11   3.145924e+11   \n",
       "2   9.630664e+12   1.025235e+13   1.058182e+13   1.093642e+13   1.145824e+13   \n",
       "3   1.685763e+12   1.662127e+12   1.643908e+12   1.784077e+12   2.057094e+12   \n",
       "4   1.252024e+12   1.143830e+12   1.167013e+12   1.270712e+12   1.574146e+12   \n",
       "\n",
       "   2004 [YR2004]  ...  2010 [YR2010]  2011 [YR2011]  2012 [YR2012]  \\\n",
       "0   2.115742e+12  ...   2.642610e+12   2.861408e+12   2.683825e+12   \n",
       "1   4.088760e+11  ...   7.769926e+11   8.387628e+11   8.805564e+11   \n",
       "2   1.221373e+13  ...   1.499205e+13   1.554258e+13   1.619701e+13   \n",
       "3   2.421814e+12  ...   2.491110e+12   2.674891e+12   2.719158e+12   \n",
       "4   1.803227e+12  ...   2.134018e+12   2.291991e+12   2.087077e+12   \n",
       "\n",
       "   2013 [YR2013]  2014 [YR2014]  2015 [YR2015]  2016 [YR2016]  2017 [YR2017]  \\\n",
       "0   2.811078e+12   2.852166e+12   2.438208e+12   2.471286e+12   2.588741e+12   \n",
       "1   9.577830e+11   9.389526e+11   8.643167e+11   8.696930e+11   8.589963e+11   \n",
       "2   1.678485e+13   1.752716e+13   1.823830e+13   1.874508e+13   1.954298e+13   \n",
       "3   2.803291e+12   3.087166e+12   2.956574e+12   2.722852e+12   2.699017e+12   \n",
       "4   2.141315e+12   2.159134e+12   1.835899e+12   1.875797e+12   1.956950e+12   \n",
       "\n",
       "   2018 [YR2018]  2019 [YR2019]  \n",
       "0   2.789594e+12   2.728870e+12  \n",
       "1   7.784719e+11   7.610044e+11  \n",
       "2   2.061186e+13   2.143322e+13  \n",
       "3   2.900791e+12   2.878674e+12  \n",
       "4   2.090911e+12   2.009384e+12  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_gdppc = pd.read_csv(\"data/gdp_gdppc.csv\")\n",
    "gdp_gdppc = gdp_gdppc[:24]\n",
    "gdp_gdppc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f2e3c-9548-44c4-abec-661b53a27560",
   "metadata": {},
   "source": [
    "Firstly, the melt function is used to unpivot the data frame to make year columns into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fa2556-bf9b-4f5a-8c36-2095ccdf9072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999 [YR1999]</td>\n",
       "      <td>1.492648e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999 [YR1999]</td>\n",
       "      <td>2.563855e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999 [YR1999]</td>\n",
       "      <td>9.630664e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999 [YR1999]</td>\n",
       "      <td>1.685763e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999 [YR1999]</td>\n",
       "      <td>1.252024e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name        Series Name           Year         Value\n",
       "0          France  GDP (current US$)  1999 [YR1999]  1.492648e+12\n",
       "1          Turkey  GDP (current US$)  1999 [YR1999]  2.563855e+11\n",
       "2   United States  GDP (current US$)  1999 [YR1999]  9.630664e+12\n",
       "3  United Kingdom  GDP (current US$)  1999 [YR1999]  1.685763e+12\n",
       "4           Italy  GDP (current US$)  1999 [YR1999]  1.252024e+12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_gdp_gdppc = ['1999 [YR1999]', '2000 [YR2000]', '2001 [YR2001]', '2002 [YR2002]',\n",
    "                   '2003 [YR2003]', '2004 [YR2004]', '2005 [YR2005]', '2006 [YR2006]',\n",
    "                   '2007 [YR2007]', '2008 [YR2008]', '2009 [YR2009]', '2010 [YR2010]',\n",
    "                   '2011 [YR2011]', '2012 [YR2012]', '2013 [YR2013]', '2014 [YR2014]',\n",
    "                   '2015 [YR2015]', '2016 [YR2016]', '2017 [YR2017]', '2018 [YR2018]',\n",
    "                   '2019 [YR2019]']\n",
    "\n",
    "gdp_gdppc = gdp_gdppc.melt(id_vars=['Country Name','Series Name'], value_vars = years_gdp_gdppc,\n",
    "                           var_name='Year', value_name='Value')\n",
    "gdp_gdppc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57b11c-fc24-495c-ae3d-948e46ec9d59",
   "metadata": {},
   "source": [
    "To arrange the 'Year' column, last 9 characters are deleted in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d87e24ee-bac4-4535-a9ce-cfd3de852e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.492648e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999</td>\n",
       "      <td>2.563855e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999</td>\n",
       "      <td>9.630664e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.685763e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.252024e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country Name        Series Name  Year         Value\n",
       "0          France  GDP (current US$)  1999  1.492648e+12\n",
       "1          Turkey  GDP (current US$)  1999  2.563855e+11\n",
       "2   United States  GDP (current US$)  1999  9.630664e+12\n",
       "3  United Kingdom  GDP (current US$)  1999  1.685763e+12\n",
       "4           Italy  GDP (current US$)  1999  1.252024e+12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_gdppc['Year'] = gdp_gdppc.apply(lambda row: row['Year'][:-9], axis=1)\n",
    "gdp_gdppc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe816d-4c6d-40a9-9f06-5423fcd03381",
   "metadata": {},
   "source": [
    "Object columns, 'Year' and 'Value' is converted to numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea17b643-18ae-40c3-a256-32ba5a9f3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_gdppc[\"Year\"] = pd.to_numeric(gdp_gdppc[\"Year\"])\n",
    "gdp_gdppc[\"Value\"] = pd.to_numeric(gdp_gdppc[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702e6f1-a4e1-4315-9800-02022c48861f",
   "metadata": {},
   "source": [
    "The pivot_table function is used to transform values in the \"Series Name\" into two columns separate as GDP and GDPP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f02b78a-ba02-4729-ac2a-59635853bb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GDP (current US$)</th>\n",
       "      <th>GDP per capita (current US$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>873.287062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.211347e+12</td>\n",
       "      <td>959.372484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.339396e+12</td>\n",
       "      <td>1053.108243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.470550e+12</td>\n",
       "      <td>1148.508290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.660288e+12</td>\n",
       "      <td>1288.643252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country Name  Year             Value                             \n",
       "Series Name                    GDP (current US$) GDP per capita (current US$)\n",
       "0                  China  1999      1.093997e+12                   873.287062\n",
       "1                  China  2000      1.211347e+12                   959.372484\n",
       "2                  China  2001      1.339396e+12                  1053.108243\n",
       "3                  China  2002      1.470550e+12                  1148.508290\n",
       "4                  China  2003      1.660288e+12                  1288.643252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_gdppc_col = pd.pivot_table(gdp_gdppc, index=[\"Country Name\",\"Year\"], columns=[\"Series Name\"]).reset_index()\n",
    "gdp_gdppc_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da1a31-3820-49cb-9862-212f776fce67",
   "metadata": {},
   "source": [
    "The level of the data frame is removed by using the droplevel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3480ab46-64df-4078-888e-363f48a4f6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP</th>\n",
       "      <th>GDP_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>873.287062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.211347e+12</td>\n",
       "      <td>959.372484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.339396e+12</td>\n",
       "      <td>1053.108243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.470550e+12</td>\n",
       "      <td>1148.508290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.660288e+12</td>\n",
       "      <td>1288.643252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Name  Year           GDP  GDP_per_capita\n",
       "0        China  1999  1.093997e+12      873.287062\n",
       "1        China  2000  1.211347e+12      959.372484\n",
       "2        China  2001  1.339396e+12     1053.108243\n",
       "3        China  2002  1.470550e+12     1148.508290\n",
       "4        China  2003  1.660288e+12     1288.643252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_gdppc_col.columns = gdp_gdppc_col.columns.droplevel()\n",
    "gdp_gdppc_col.columns = ['Country_Name', 'Year', 'GDP', 'GDP_per_capita']\n",
    "gdp_gdppc_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4485d0-2b9e-4e70-b499-639699bcbfdb",
   "metadata": {},
   "source": [
    "Finally, the distance data set is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cc06d26-076f-4724-9eec-c0b75e317059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp country</th>\n",
       "      <th>country_j</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>China</td>\n",
       "      <td>6083.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>France</td>\n",
       "      <td>2803.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2332.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>4433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1911.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Exp country country_j  distance\n",
       "0      Turkey     China   6083.43\n",
       "1      Turkey    France   2803.41\n",
       "2      Turkey   Germany   2332.79\n",
       "3      Turkey   Iceland   4433.00\n",
       "4      Turkey     Italy   1911.13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = pd.read_csv(\"data/distance.csv\")\n",
    "distance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e448d1-5b1d-4a24-aa38-18ca564f8eb7",
   "metadata": {},
   "source": [
    "The distance and previous year's export, GDP, and GDPPC values are needed to add the export_data data frame. To add them row by row, while doing loop, the itterrows function is used to keep the index number and values in that row. Thus, with the help of the \"at\" function, the value in the row can be added to the relevant index of the export_data data frame.  \n",
    "\n",
    "Firstly, the previous year's export value in the export_data_all data frame is added to export_data. Following, the previous year's GDP and GDPPC values in the gdp_gdppc_col data frame are added according to the export and import countries in that row. Finally, distance is added between countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20b15f62-5f53-4c3a-a29c-0a8a84235c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>91336.496</td>\n",
       "      <td>36637.176</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>6083.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>France</td>\n",
       "      <td>2000</td>\n",
       "      <td>1651591.721</td>\n",
       "      <td>1573188.736</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2803.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2000</td>\n",
       "      <td>5171172.501</td>\n",
       "      <td>5474533.888</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2332.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2000</td>\n",
       "      <td>4941.386</td>\n",
       "      <td>2333.333</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>4433.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2000</td>\n",
       "      <td>1755168.844</td>\n",
       "      <td>1682516.992</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>1911.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Export   Import  Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)  \\\n",
       "11  Turkey    China  2000     91336.496           36637.176  2.563855e+11   \n",
       "12  Turkey   France  2000   1651591.721         1573188.736  2.563855e+11   \n",
       "13  Turkey  Germany  2000   5171172.501         5474533.888  2.563855e+11   \n",
       "14  Turkey  Iceland  2000      4941.386            2333.333  2.563855e+11   \n",
       "15  Turkey    Italy  2000   1755168.844         1682516.992  2.563855e+11   \n",
       "\n",
       "      GDP_j(t-1)  GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  \n",
       "11  1.093997e+12    4116.17056    873.287062  6083.43  \n",
       "12  1.492648e+12    4116.17056  24673.203048  2803.41  \n",
       "13  2.194204e+12    4116.17056  26725.915218  2332.79  \n",
       "14  8.982048e+09    4116.17056  32381.625236  4433.00  \n",
       "15  1.252024e+12    4116.17056  21997.624316  1911.13  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in export_data.iterrows():\n",
    "    \n",
    "    export_data.at[index,'Export_Value_(t-1)'] = export_data_all[(export_data_all['Export']==row['Export']) &\n",
    "                                                                 (export_data_all['Import']==row['Import']) &\n",
    "                                                                 (export_data_all['Year']==(row['Year']-1))]['Export_Value'].values\n",
    "    \n",
    "    export_data.at[index,'GDP_i(t-1)'] = gdp_gdppc_col[(gdp_gdppc_col['Country_Name']==row['Export']) &\n",
    "                                                       (gdp_gdppc_col['Year']==(row['Year']-1))]['GDP'].values\n",
    "    export_data.at[index,'GDP_j(t-1)'] = gdp_gdppc_col[(gdp_gdppc_col['Country_Name']==row['Import']) &\n",
    "                                                       (gdp_gdppc_col['Year']==(row['Year']-1))]['GDP'].values\n",
    "    \n",
    "    export_data.at[index,'GDPPC_i(t-1)'] = gdp_gdppc_col[(gdp_gdppc_col['Country_Name']==row['Export']) &\n",
    "                                                         (gdp_gdppc_col['Year']==(row['Year']-1))]['GDP_per_capita'].values\n",
    "    export_data.at[index,'GDPPC_j(t-1)'] = gdp_gdppc_col[(gdp_gdppc_col['Country_Name']==row['Import']) &\n",
    "                                                         (gdp_gdppc_col['Year']==(row['Year']-1))]['GDP_per_capita'].values\n",
    "    \n",
    "    export_data.at[index,'D_ij'] = distance[(distance['Exp country']==row['Export']) &\n",
    "                                            (distance['country_j']==row['Import'])]['distance'].values\n",
    "export_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ff97d-aa28-4aa5-88d3-dfc93db80619",
   "metadata": {},
   "source": [
    "After the addition process, the index is reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb287a5-4708-40cb-948a-c3311fa2750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = export_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129d4cd-0152-4ac4-9303-b004839c13fb",
   "metadata": {},
   "source": [
    "Countries are assigned to list as member and nonmember by their membership status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "370d1053-f588-4bc1-b4b3-5460261ad4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "member = [\"Turkey\", \"Norway\", \"Iceland\", \"Switzerland\"]\n",
    "nonmember = [\"China\", \"Italy\", \"Germany\", \"France\", \"Spain\",\n",
    "             \"United Kingdom\", \"United States\", \"Netherlands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ecf6b-fadd-43d9-a35c-245f4b577818",
   "metadata": {},
   "source": [
    "To indicate if both countries are members of EFTA-Turkey FTA, a dummy column is added. It takes the value 1, otherwise, it takes the value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1188315f-032a-4240-a643-3db54042350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_1 = []\n",
    "\n",
    "for i in range(export_data.shape[0]):\n",
    "    if(export_data[\"Export\"][i] in member and export_data[\"Import\"][i] in member):\n",
    "        dummy_1.append(1)\n",
    "    else:\n",
    "        dummy_1.append(0)\n",
    "        \n",
    "export_data[\"FTA_1\"] = dummy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8500a1-7966-4413-bb47-56e70e3726ea",
   "metadata": {},
   "source": [
    "The second dummy takes the value 1 if the exporting country is a member of EFTA-Turkey FTA, but the importing country is not a member of EFTA-Turkey FTA, otherwise, it takes the value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "564d5d75-1f98-42e5-9171-160d2c38b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_2 = []\n",
    "\n",
    "for i in range(export_data.shape[0]):\n",
    "    if(export_data[\"Export\"][i] in member and export_data[\"Import\"][i] in nonmember):\n",
    "        dummy_2.append(1)\n",
    "    else:\n",
    "        dummy_2.append(0)\n",
    "        \n",
    "export_data[\"FTA_2\"] = dummy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e3d4b0e-0923-4e3d-ae68-56b1fd2b4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>91336.496</td>\n",
       "      <td>36637.176</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>6083.43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>France</td>\n",
       "      <td>2000</td>\n",
       "      <td>1651591.721</td>\n",
       "      <td>1573188.736</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2803.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2000</td>\n",
       "      <td>5171172.501</td>\n",
       "      <td>5474533.888</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2332.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2000</td>\n",
       "      <td>4941.386</td>\n",
       "      <td>2333.333</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>4433.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2000</td>\n",
       "      <td>1755168.844</td>\n",
       "      <td>1682516.992</td>\n",
       "      <td>2.563855e+11</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>4116.17056</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>1911.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Export   Import  Year  Export_Value  Export_Value_(t-1)  \\\n",
       "0     11  Turkey    China  2000     91336.496           36637.176   \n",
       "1     12  Turkey   France  2000   1651591.721         1573188.736   \n",
       "2     13  Turkey  Germany  2000   5171172.501         5474533.888   \n",
       "3     14  Turkey  Iceland  2000      4941.386            2333.333   \n",
       "4     15  Turkey    Italy  2000   1755168.844         1682516.992   \n",
       "\n",
       "     GDP_i(t-1)    GDP_j(t-1)  GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  \\\n",
       "0  2.563855e+11  1.093997e+12    4116.17056    873.287062  6083.43      0   \n",
       "1  2.563855e+11  1.492648e+12    4116.17056  24673.203048  2803.41      0   \n",
       "2  2.563855e+11  2.194204e+12    4116.17056  26725.915218  2332.79      0   \n",
       "3  2.563855e+11  8.982048e+09    4116.17056  32381.625236  4433.00      1   \n",
       "4  2.563855e+11  1.252024e+12    4116.17056  21997.624316  1911.13      0   \n",
       "\n",
       "   FTA_2  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f7b98-923c-4cf7-85f6-5b0773c8aa45",
   "metadata": {},
   "source": [
    "The column called ‘index’ is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7666f99-aed4-49aa-b13c-a523454c9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = export_data.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a9d0d-1acf-4913-b006-3da09758c145",
   "metadata": {},
   "source": [
    "The data set is sorted by year, exporting country and importing country, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a349bba-84f4-4263-862a-4ca45b8d2b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>11191.652</td>\n",
       "      <td>5022.337</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>7861.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>France</td>\n",
       "      <td>2000</td>\n",
       "      <td>87202.089</td>\n",
       "      <td>104187.632</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2372.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2000</td>\n",
       "      <td>312116.389</td>\n",
       "      <td>262963.856</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2246.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2000</td>\n",
       "      <td>27966.976</td>\n",
       "      <td>34470.260</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>3138.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2000</td>\n",
       "      <td>147015.380</td>\n",
       "      <td>120782.848</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4.468986e+11</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>28263.096711</td>\n",
       "      <td>1932.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Export       Import  Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)  \\\n",
       "0  Iceland        China  2000     11191.652            5022.337  8.982048e+09   \n",
       "1  Iceland       France  2000     87202.089          104187.632  8.982048e+09   \n",
       "2  Iceland      Germany  2000    312116.389          262963.856  8.982048e+09   \n",
       "3  Iceland        Italy  2000     27966.976           34470.260  8.982048e+09   \n",
       "4  Iceland  Netherlands  2000    147015.380          120782.848  8.982048e+09   \n",
       "\n",
       "     GDP_j(t-1)  GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  FTA_2  \n",
       "0  1.093997e+12  32381.625236    873.287062  7861.07      0      1  \n",
       "1  1.492648e+12  32381.625236  24673.203048  2372.32      0      1  \n",
       "2  2.194204e+12  32381.625236  26725.915218  2246.80      0      1  \n",
       "3  1.252024e+12  32381.625236  21997.624316  3138.62      0      1  \n",
       "4  4.468986e+11  32381.625236  28263.096711  1932.09      0      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_data.sort_values(['Year', 'Export', 'Import'], inplace=True)\n",
    "export_data = export_data.reset_index().drop('index', axis=1)\n",
    "export_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e72636-1e5e-4010-ae0c-bb89689bdead",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#351C75\">6.4. Models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d27117-261b-4fee-93fe-84edb9ecf71e",
   "metadata": {},
   "source": [
    "After the data set has been created as wanted, the next step is to build models around the data to predict next year’s export values. The aim of the project is to decide which model will give the best result by comparing error values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46348c97-e21d-499d-bc23-9a49cf77e4a5",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">6.4.1. LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f880ac-9c11-4f7b-a32e-73914d600854",
   "metadata": {},
   "source": [
    "Firstly, three models are created using LSTM. Base is the model without including categorical values which are country pairs. Also, there are models with one-hot and label encoding that include categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c52222-7055-49b7-959a-513cf3a5c7fa",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">6.4.1.1. LSTM Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adb4d3-ade1-4369-a6f4-3cecac0d2449",
   "metadata": {},
   "source": [
    "In this section, all the codes been displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00b3082a-baa2-4ef3-a9e5-bdc8aac467b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b582475-d17e-46fb-9c8d-c39f973e0a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Export</th>\n",
       "      <th>Import</th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>China</td>\n",
       "      <td>2000</td>\n",
       "      <td>11191.652</td>\n",
       "      <td>5022.337</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>7861.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>France</td>\n",
       "      <td>2000</td>\n",
       "      <td>87202.089</td>\n",
       "      <td>104187.632</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2372.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2000</td>\n",
       "      <td>312116.389</td>\n",
       "      <td>262963.856</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2246.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2000</td>\n",
       "      <td>27966.976</td>\n",
       "      <td>34470.260</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>3138.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2000</td>\n",
       "      <td>147015.380</td>\n",
       "      <td>120782.848</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4.468986e+11</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>28263.096711</td>\n",
       "      <td>1932.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Export       Import  Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)  \\\n",
       "0  Iceland        China  2000     11191.652            5022.337  8.982048e+09   \n",
       "1  Iceland       France  2000     87202.089          104187.632  8.982048e+09   \n",
       "2  Iceland      Germany  2000    312116.389          262963.856  8.982048e+09   \n",
       "3  Iceland        Italy  2000     27966.976           34470.260  8.982048e+09   \n",
       "4  Iceland  Netherlands  2000    147015.380          120782.848  8.982048e+09   \n",
       "\n",
       "     GDP_j(t-1)  GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  FTA_2  \n",
       "0  1.093997e+12  32381.625236    873.287062  7861.07      0      1  \n",
       "1  1.492648e+12  32381.625236  24673.203048  2372.32      0      1  \n",
       "2  2.194204e+12  32381.625236  26725.915218  2246.80      0      1  \n",
       "3  1.252024e+12  32381.625236  21997.624316  3138.62      0      1  \n",
       "4  4.468986e+11  32381.625236  28263.096711  1932.09      0      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c5920-b34e-4672-92e7-166cd45705bf",
   "metadata": {},
   "source": [
    "After importing the final data set, from the year column, 2000 is subtracted to work with smaller values. Additionally, the \"Export\" and \"Import\" columns are dropped, since they will not use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ffd3e15-f960-4fa1-814f-15d1b3bba471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"] = df[\"Year\"]-2000\n",
    "df.drop([\"Export\",\"Import\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7a595-2d83-4dcc-bcd3-fad7af49d8ff",
   "metadata": {},
   "source": [
    "Since the variables have different ranges of values, scaling is needed to get an efficient result. Due to dealing with economic data, the natural logarithm is taken of the columns in the 'columns' list to normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "239a39f8-bcd5-4ef6-9ae6-4f7edd487efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.322923</td>\n",
       "      <td>8.521651</td>\n",
       "      <td>22.918494</td>\n",
       "      <td>27.720859</td>\n",
       "      <td>10.385346</td>\n",
       "      <td>6.772264</td>\n",
       "      <td>8.969678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.375984</td>\n",
       "      <td>11.553949</td>\n",
       "      <td>22.918494</td>\n",
       "      <td>28.031573</td>\n",
       "      <td>10.385346</td>\n",
       "      <td>10.113473</td>\n",
       "      <td>7.771624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.651131</td>\n",
       "      <td>12.479772</td>\n",
       "      <td>22.918494</td>\n",
       "      <td>28.416841</td>\n",
       "      <td>10.385346</td>\n",
       "      <td>10.193389</td>\n",
       "      <td>7.717262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.238780</td>\n",
       "      <td>10.447852</td>\n",
       "      <td>22.918494</td>\n",
       "      <td>27.855782</td>\n",
       "      <td>10.385346</td>\n",
       "      <td>9.998690</td>\n",
       "      <td>8.051538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11.898292</td>\n",
       "      <td>11.701750</td>\n",
       "      <td>22.918494</td>\n",
       "      <td>26.825597</td>\n",
       "      <td>10.385346</td>\n",
       "      <td>10.249312</td>\n",
       "      <td>7.566358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Export_Value  Export_Value_(t-1)  GDP_i(t-1)  GDP_j(t-1)  \\\n",
       "0     0      9.322923            8.521651   22.918494   27.720859   \n",
       "1     0     11.375984           11.553949   22.918494   28.031573   \n",
       "2     0     12.651131           12.479772   22.918494   28.416841   \n",
       "3     0     10.238780           10.447852   22.918494   27.855782   \n",
       "4     0     11.898292           11.701750   22.918494   26.825597   \n",
       "\n",
       "   GDPPC_i(t-1)  GDPPC_j(t-1)      D_ij  FTA_1  FTA_2  \n",
       "0     10.385346      6.772264  8.969678      0      1  \n",
       "1     10.385346     10.113473  7.771624      0      1  \n",
       "2     10.385346     10.193389  7.717262      0      1  \n",
       "3     10.385346      9.998690  8.051538      0      1  \n",
       "4     10.385346     10.249312  7.566358      0      1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns] = df[columns].apply(lambda x: np.log(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e2850-9304-43f1-9f5d-9ff583781f9c",
   "metadata": {},
   "source": [
    "After taking the natural logarithm of the columns, min-max normalization is applied to obtain smaller numbers. Fit_transform() is a combination of fit and transform method. The fit method computes the mean and standard deviation of the feature and the transform method applies these calculations to every data point for each feature. Since only the target value which is Export_Value, is needed to calculate the error after the model prediction, MinMaxScaler() is applied for normalization which is scaling each data point with *Equation 21*:\n",
    "\n",
    "$$ k = {x - min \\over max - min}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98bb1e27-f674-4059-bc9f-a3b296c3cf69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.239215</td>\n",
       "      <td>0.166455</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.624801</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915914</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.426011</td>\n",
       "      <td>0.442586</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.664507</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.700554</td>\n",
       "      <td>0.522239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.542030</td>\n",
       "      <td>0.526894</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.713741</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.717310</td>\n",
       "      <td>0.504376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.322544</td>\n",
       "      <td>0.341861</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.642043</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.676487</td>\n",
       "      <td>0.614218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.473533</td>\n",
       "      <td>0.456045</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.510394</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>0.729036</td>\n",
       "      <td>0.454790</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Export_Value  Export_Value_(t-1)  GDP_i(t-1)  GDP_j(t-1)  \\\n",
       "0     0      0.239215            0.166455    0.018261    0.624801   \n",
       "1     0      0.426011            0.442586    0.018261    0.664507   \n",
       "2     0      0.542030            0.526894    0.018261    0.713741   \n",
       "3     0      0.322544            0.341861    0.018261    0.642043   \n",
       "4     0      0.473533            0.456045    0.018261    0.510394   \n",
       "\n",
       "   GDPPC_i(t-1)  GDPPC_j(t-1)      D_ij  FTA_1  FTA_2  \n",
       "0      0.668563      0.000000  0.915914      0      1  \n",
       "1      0.668563      0.700554  0.522239      0      1  \n",
       "2      0.668563      0.717310  0.504376      0      1  \n",
       "3      0.668563      0.676487  0.614218      0      1  \n",
       "4      0.668563      0.729036  0.454790      0      1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value']= min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "\n",
    "columns_mms=['Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9383de-d559-4dec-bcf6-048952412ca4",
   "metadata": {},
   "source": [
    "The data set is divided into target value and features for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8da9afaf-be4a-45fa-a75d-2f9410229d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = df['Export_Value'].values\n",
    "x_values = df.drop('Export_Value',axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad63c1-3314-494b-93a6-f982ee2ea180",
   "metadata": {},
   "source": [
    "The data set is split into training, validation, and testing. In time series, the order of the dataset is important. The training, validation, and test dataset has rows from 2000 to 2016, from 2017 to 2018, and 2019, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee71c6d5-9564-42ba-96a3-18109c06bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca5479-65c7-41c3-8219-5af8f43030af",
   "metadata": {},
   "source": [
    "LSTM takes the input layer in three dimensions as samples, time steps, and features. So, x and y values are reshaped from 2-dimension to 3-dimension. The Time step represents how many rows the model will go back while learning. If the time step takes the value 1, it implies that it will look at only the current row. For instance, if the time step is 3, the model will look from the current row to two previous rows to learn.  \n",
    "\n",
    "The time step is given value 1 because a higher error value is received when the timestep is different from value 1. Since country pairs repeat every 44 rows, especially the value of 44 has been considered for timestep value. However, as stated before, value 44 did not give as good results as value 1. When tested with value 1, obtained error values were between 0.4 and 0.6, but while tested with 44, obtained error values were bigger than 1. Moreover, since the previous year's data is taken as features while preparing the data, LSTM already estimates the export value based on the previous year's data when it only looks at the current row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19841011-3077-4760-8753-ccef47083d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 1, 9) (748, 1) (88, 1, 9) (88, 1) (44, 1, 9) (44, 1)\n"
     ]
    }
   ],
   "source": [
    "timesteps = 1\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0]//timesteps, timesteps, train_X.shape[1]))\n",
    "validation_X = validation_X.reshape((validation_X.shape[0]//timesteps, timesteps, validation_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0]//timesteps, timesteps, test_X.shape[1]))\n",
    "\n",
    "train_y = train_y.reshape((train_y.shape[0]//timesteps, timesteps,))\n",
    "validation_y = validation_y.reshape((validation_y.shape[0]//timesteps, timesteps,))\n",
    "test_y =  test_y.reshape((test_y.shape[0]//timesteps, timesteps,))\n",
    "\n",
    "print(train_X.shape, train_y.shape, validation_X.shape, validation_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbff4f-d0de-492a-b0c3-cd34cfadced5",
   "metadata": {},
   "source": [
    "There is a function called Sequential() to build models layer by layer in Keras. Each layer is followed by the next layer with its corresponding weights. The add function is used for adding layers to the model. [[11]](https://medium.com/ai-techsystems/mushroom-classification-using-deep-learning-e0154afa4c03)  \n",
    "\n",
    "On the first hidden layer, the LSTMs input layer should be defined with the input_shape argument. Two values are required for the input shape argument: the number of time steps and the number of features. LSTM presumes that the sample number is 1 or greater. [[12]](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/)  \n",
    "\n",
    "The dense class is applied for connecting layers. In the first argument of the Dense class, the number of neurons in the output layer is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b898cad-a889-4d2a-8793-e6ca1c225f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da5bbe-47ad-4c5e-8287-fc59fdcb5365",
   "metadata": {},
   "source": [
    "The loss function is needed to be specified for evaluating weights according to it. The optimizer adam which is some sort of Stochastic Gradient Descent (SGD) is used for the computation of the gradient and it will update the weights in small batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60440595-1746-4618-bb0e-d43fed4e7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13395e-c412-4ed4-bd5c-e992bea2ffb3",
   "metadata": {},
   "source": [
    "While training the model, the number of epochs to apply is a crucial issue. If the number of epochs is high, the developed model may be over-fitting for the training dataset, while using less may result in underfitting. This problem can be avoided by applying the early stopping method. On model.fit, argument “epochs” are mostly given as large numbers. The early stopping stops training of the model when it realizes the model has already learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2be48ea-8fd2-4c15-9474-a5de25c03b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035746b-887a-4c5c-940e-c9314c536001",
   "metadata": {},
   "source": [
    "The model has been specified and compiled; therefore, it is now ready for efficient computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbbc9cdf-2fda-4db4-86b9-dfefb20368c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "24/24 - 2s - loss: 0.2723 - val_loss: 0.1923 - 2s/epoch - 68ms/step\n",
      "Epoch 2/200\n",
      "24/24 - 0s - loss: 0.1366 - val_loss: 0.1042 - 48ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "24/24 - 0s - loss: 0.0658 - val_loss: 0.0573 - 53ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "24/24 - 0s - loss: 0.0409 - val_loss: 0.0413 - 55ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "24/24 - 0s - loss: 0.0354 - val_loss: 0.0377 - 48ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "24/24 - 0s - loss: 0.0324 - val_loss: 0.0366 - 51ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "24/24 - 0s - loss: 0.0297 - val_loss: 0.0352 - 50ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "24/24 - 0s - loss: 0.0273 - val_loss: 0.0333 - 52ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "24/24 - 0s - loss: 0.0252 - val_loss: 0.0313 - 49ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "24/24 - 0s - loss: 0.0231 - val_loss: 0.0292 - 49ms/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "24/24 - 0s - loss: 0.0213 - val_loss: 0.0270 - 51ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "24/24 - 0s - loss: 0.0196 - val_loss: 0.0248 - 48ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "24/24 - 0s - loss: 0.0181 - val_loss: 0.0227 - 50ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "24/24 - 0s - loss: 0.0168 - val_loss: 0.0207 - 63ms/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "24/24 - 0s - loss: 0.0156 - val_loss: 0.0190 - 63ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "24/24 - 0s - loss: 0.0145 - val_loss: 0.0174 - 49ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "24/24 - 0s - loss: 0.0135 - val_loss: 0.0160 - 51ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "24/24 - 0s - loss: 0.0126 - val_loss: 0.0148 - 48ms/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "24/24 - 0s - loss: 0.0117 - val_loss: 0.0138 - 49ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "24/24 - 0s - loss: 0.0109 - val_loss: 0.0128 - 51ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "24/24 - 0s - loss: 0.0102 - val_loss: 0.0119 - 51ms/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "24/24 - 0s - loss: 0.0095 - val_loss: 0.0112 - 51ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "24/24 - 0s - loss: 0.0088 - val_loss: 0.0104 - 54ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "24/24 - 0s - loss: 0.0082 - val_loss: 0.0098 - 47ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "24/24 - 0s - loss: 0.0077 - val_loss: 0.0092 - 51ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "24/24 - 0s - loss: 0.0072 - val_loss: 0.0087 - 57ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "24/24 - 0s - loss: 0.0068 - val_loss: 0.0082 - 59ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "24/24 - 0s - loss: 0.0064 - val_loss: 0.0077 - 53ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "24/24 - 0s - loss: 0.0061 - val_loss: 0.0073 - 49ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "24/24 - 0s - loss: 0.0058 - val_loss: 0.0071 - 48ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "24/24 - 0s - loss: 0.0056 - val_loss: 0.0069 - 52ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "24/24 - 0s - loss: 0.0054 - val_loss: 0.0067 - 59ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "24/24 - 0s - loss: 0.0052 - val_loss: 0.0065 - 51ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "24/24 - 0s - loss: 0.0051 - val_loss: 0.0064 - 48ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "24/24 - 0s - loss: 0.0049 - val_loss: 0.0062 - 49ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "24/24 - 0s - loss: 0.0048 - val_loss: 0.0061 - 51ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "24/24 - 0s - loss: 0.0046 - val_loss: 0.0060 - 56ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "24/24 - 0s - loss: 0.0045 - val_loss: 0.0059 - 52ms/epoch - 2ms/step\n",
      "Epoch 39/200\n",
      "24/24 - 0s - loss: 0.0044 - val_loss: 0.0058 - 48ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "24/24 - 0s - loss: 0.0043 - val_loss: 0.0056 - 49ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "24/24 - 0s - loss: 0.0041 - val_loss: 0.0055 - 51ms/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "24/24 - 0s - loss: 0.0040 - val_loss: 0.0054 - 53ms/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "24/24 - 0s - loss: 0.0039 - val_loss: 0.0053 - 55ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "24/24 - 0s - loss: 0.0038 - val_loss: 0.0052 - 60ms/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "24/24 - 0s - loss: 0.0037 - val_loss: 0.0051 - 64ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "24/24 - 0s - loss: 0.0036 - val_loss: 0.0050 - 58ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "24/24 - 0s - loss: 0.0035 - val_loss: 0.0049 - 57ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "24/24 - 0s - loss: 0.0034 - val_loss: 0.0048 - 58ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "24/24 - 0s - loss: 0.0033 - val_loss: 0.0047 - 61ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "24/24 - 0s - loss: 0.0032 - val_loss: 0.0046 - 58ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "24/24 - 0s - loss: 0.0032 - val_loss: 0.0044 - 59ms/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "24/24 - 0s - loss: 0.0031 - val_loss: 0.0043 - 60ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "24/24 - 0s - loss: 0.0030 - val_loss: 0.0042 - 64ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "24/24 - 0s - loss: 0.0029 - val_loss: 0.0041 - 57ms/epoch - 2ms/step\n",
      "Epoch 55/200\n",
      "24/24 - 0s - loss: 0.0028 - val_loss: 0.0040 - 49ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "24/24 - 0s - loss: 0.0027 - val_loss: 0.0039 - 51ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "24/24 - 0s - loss: 0.0027 - val_loss: 0.0038 - 57ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "24/24 - 0s - loss: 0.0026 - val_loss: 0.0037 - 50ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "24/24 - 0s - loss: 0.0025 - val_loss: 0.0036 - 55ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "24/24 - 0s - loss: 0.0024 - val_loss: 0.0035 - 47ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "24/24 - 0s - loss: 0.0024 - val_loss: 0.0034 - 48ms/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0034 - 49ms/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0033 - 63ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0032 - 62ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0032 - 51ms/epoch - 2ms/step\n",
      "Epoch 66/200\n",
      "24/24 - 0s - loss: 0.0021 - val_loss: 0.0032 - 49ms/epoch - 2ms/step\n",
      "Epoch 67/200\n",
      "24/24 - 0s - loss: 0.0021 - val_loss: 0.0032 - 50ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "24/24 - 0s - loss: 0.0021 - val_loss: 0.0032 - 50ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "24/24 - 0s - loss: 0.0020 - val_loss: 0.0032 - 48ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "24/24 - 0s - loss: 0.0020 - val_loss: 0.0032 - 49ms/epoch - 2ms/step\n",
      "Epoch 00070: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=200, batch_size=None,\n",
    "                    validation_data=(validation_X, validation_y), shuffle=False,\n",
    "                    callbacks=[es], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecd436-0a38-439a-8c0e-067d46855aef",
   "metadata": {},
   "source": [
    "After the model building, for each model, learning curves are displayed. Learning curves are graphs that indicate how learning performance has changed over epochs. It helps to see how the model learns.  \n",
    "\n",
    "Y-axis shows loss which is the mean squared error value while the x-axis shows epochs. *Figure 11* shows the comparison of training data and validation data. It shows the decrease in the loss by epochs.  \n",
    "\n",
    "The training loss curve is the learning curve calculated from the training dataset that gives an idea about how well the model is learning. The validation loss curve is the learning curve calculated from the validation dataset that gives an idea about how well the model is generalizing. Training and validation loss that decreases to a point of stability with minimal gap between the two final loss values defined as good-fit. [[13]](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06a4ddc1-3c44-4504-a200-87357b5ff7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695a959-076d-4b73-a177-d3874bbb19eb",
   "metadata": {},
   "source": [
    "LSTM model makes a prediction with help of the predict function in the Keras library. Since the model takes scaled values, it also estimates in this value range. Therefore, back scaling is needed to obtain true value. But, because of dealing with economic data, only the inverse transformation of min-max scaling is taken. Thus, in this case, values are still in logarithmic form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c05f819b-3dc6-4428-a38e-5007a1894bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(test_X)\n",
    "inv_yhat = min_max_scaler_y.inverse_transform(yhat)\n",
    "test_y = test_y.reshape((len(test_y)*timesteps, 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y)\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697250d-db52-4477-a5e2-f27bdb36de4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The learning curve of the LSTM one-hot encoding model showed in the plot above. The calculated result for root mean squared error (RMSE) is 0.605."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56751fd-7d4e-41db-8822-074a2c490325",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">6.4.1.2. LSTM Model Using One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76c9ba7d-6054-42d6-81de-8ebec624d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b2a5c-6ecf-4d39-9fae-5d5db7df87c2",
   "metadata": {},
   "source": [
    "Since the Export and Import columns are categorical, to use these variables in the model, it is necessary to convert them into numerical values. The term one-hot encoding means that categorical variables are represented in binary form such as 0s and 1s.  \n",
    "\n",
    "In order to apply one-hot encoding, 44 country pairs are created by combining the names of importing and exporting countries. After this process, the Export and Import columns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f826698e-bb24-4348-8d4d-ceab65426a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "      <th>CountryPairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>11191.652</td>\n",
       "      <td>5022.337</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>7861.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandChina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>87202.089</td>\n",
       "      <td>104187.632</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2372.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandFrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>312116.389</td>\n",
       "      <td>262963.856</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2246.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandGermany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>27966.976</td>\n",
       "      <td>34470.260</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>3138.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandItaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>147015.380</td>\n",
       "      <td>120782.848</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4.468986e+11</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>28263.096711</td>\n",
       "      <td>1932.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandNetherlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)    GDP_j(t-1)  \\\n",
       "0  2000     11191.652            5022.337  8.982048e+09  1.093997e+12   \n",
       "1  2000     87202.089          104187.632  8.982048e+09  1.492648e+12   \n",
       "2  2000    312116.389          262963.856  8.982048e+09  2.194204e+12   \n",
       "3  2000     27966.976           34470.260  8.982048e+09  1.252024e+12   \n",
       "4  2000    147015.380          120782.848  8.982048e+09  4.468986e+11   \n",
       "\n",
       "   GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  FTA_2        CountryPairs  \n",
       "0  32381.625236    873.287062  7861.07      0      1        IcelandChina  \n",
       "1  32381.625236  24673.203048  2372.32      0      1       IcelandFrance  \n",
       "2  32381.625236  26725.915218  2246.80      0      1      IcelandGermany  \n",
       "3  32381.625236  21997.624316  3138.62      0      1        IcelandItaly  \n",
       "4  32381.625236  28263.096711  1932.09      0      1  IcelandNetherlands  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CountryPairs\"] = df[\"Export\"] + df[\"Import\"]\n",
    "df.drop([\"Export\", \"Import\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d1ed7-ca03-465d-b19b-98a558bed48e",
   "metadata": {},
   "source": [
    "After this process, by using the get_dummies function from Pandas library, these variables will turn into one-hot encoding form. In one-hot encoding, with dummies, 44 columns will be added to the data. These dummies, for every country pair, will convert the categorical value into numerical value. The value will be 1 if the country pair on that row is itself, otherwise 0 as seen below. In this way, the model can understand the importance of country pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf887717-41d9-4f03-9855-6cc081474f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryPairs_IcelandChina</th>\n",
       "      <th>CountryPairs_IcelandFrance</th>\n",
       "      <th>CountryPairs_IcelandGermany</th>\n",
       "      <th>CountryPairs_IcelandItaly</th>\n",
       "      <th>CountryPairs_IcelandNetherlands</th>\n",
       "      <th>CountryPairs_IcelandNorway</th>\n",
       "      <th>CountryPairs_IcelandSpain</th>\n",
       "      <th>CountryPairs_IcelandSwitzerland</th>\n",
       "      <th>CountryPairs_IcelandTurkey</th>\n",
       "      <th>CountryPairs_IcelandUnited Kingdom</th>\n",
       "      <th>...</th>\n",
       "      <th>CountryPairs_TurkeyFrance</th>\n",
       "      <th>CountryPairs_TurkeyGermany</th>\n",
       "      <th>CountryPairs_TurkeyIceland</th>\n",
       "      <th>CountryPairs_TurkeyItaly</th>\n",
       "      <th>CountryPairs_TurkeyNetherlands</th>\n",
       "      <th>CountryPairs_TurkeyNorway</th>\n",
       "      <th>CountryPairs_TurkeySpain</th>\n",
       "      <th>CountryPairs_TurkeySwitzerland</th>\n",
       "      <th>CountryPairs_TurkeyUnited Kingdom</th>\n",
       "      <th>CountryPairs_TurkeyUnited States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountryPairs_IcelandChina  CountryPairs_IcelandFrance  \\\n",
       "0                          1                           0   \n",
       "1                          0                           1   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   CountryPairs_IcelandGermany  CountryPairs_IcelandItaly  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            1                          0   \n",
       "3                            0                          1   \n",
       "4                            0                          0   \n",
       "\n",
       "   CountryPairs_IcelandNetherlands  CountryPairs_IcelandNorway  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                1                           0   \n",
       "\n",
       "   CountryPairs_IcelandSpain  CountryPairs_IcelandSwitzerland  \\\n",
       "0                          0                                0   \n",
       "1                          0                                0   \n",
       "2                          0                                0   \n",
       "3                          0                                0   \n",
       "4                          0                                0   \n",
       "\n",
       "   CountryPairs_IcelandTurkey  CountryPairs_IcelandUnited Kingdom  ...  \\\n",
       "0                           0                                   0  ...   \n",
       "1                           0                                   0  ...   \n",
       "2                           0                                   0  ...   \n",
       "3                           0                                   0  ...   \n",
       "4                           0                                   0  ...   \n",
       "\n",
       "   CountryPairs_TurkeyFrance  CountryPairs_TurkeyGermany  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   CountryPairs_TurkeyIceland  CountryPairs_TurkeyItaly  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   CountryPairs_TurkeyNetherlands  CountryPairs_TurkeyNorway  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "\n",
       "   CountryPairs_TurkeySpain  CountryPairs_TurkeySwitzerland  \\\n",
       "0                         0                               0   \n",
       "1                         0                               0   \n",
       "2                         0                               0   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "\n",
       "   CountryPairs_TurkeyUnited Kingdom  CountryPairs_TurkeyUnited States  \n",
       "0                                  0                                 0  \n",
       "1                                  0                                 0  \n",
       "2                                  0                                 0  \n",
       "3                                  0                                 0  \n",
       "4                                  0                                 0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df.iloc[:,10:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f950ecf6-9160-4430-94d2-6ec296d2e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 - 2s - loss: 0.3009 - val_loss: 0.0985 - 2s/epoch - 64ms/step\n",
      "Epoch 2/30\n",
      "24/24 - 0s - loss: 0.0939 - val_loss: 0.0366 - 54ms/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "24/24 - 0s - loss: 0.0498 - val_loss: 0.0453 - 47ms/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "24/24 - 0s - loss: 0.0368 - val_loss: 0.0367 - 52ms/epoch - 2ms/step\n",
      "Epoch 5/30\n",
      "24/24 - 0s - loss: 0.0292 - val_loss: 0.0289 - 47ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "24/24 - 0s - loss: 0.0235 - val_loss: 0.0243 - 51ms/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "24/24 - 0s - loss: 0.0189 - val_loss: 0.0209 - 46ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "24/24 - 0s - loss: 0.0153 - val_loss: 0.0183 - 51ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "24/24 - 0s - loss: 0.0124 - val_loss: 0.0161 - 46ms/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "24/24 - 0s - loss: 0.0101 - val_loss: 0.0142 - 50ms/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "24/24 - 0s - loss: 0.0082 - val_loss: 0.0125 - 45ms/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "24/24 - 0s - loss: 0.0067 - val_loss: 0.0109 - 50ms/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "24/24 - 0s - loss: 0.0054 - val_loss: 0.0095 - 52ms/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "24/24 - 0s - loss: 0.0045 - val_loss: 0.0082 - 51ms/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "24/24 - 0s - loss: 0.0037 - val_loss: 0.0072 - 48ms/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "24/24 - 0s - loss: 0.0031 - val_loss: 0.0063 - 52ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "24/24 - 0s - loss: 0.0026 - val_loss: 0.0056 - 49ms/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0050 - 51ms/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "24/24 - 0s - loss: 0.0019 - val_loss: 0.0045 - 49ms/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "24/24 - 0s - loss: 0.0017 - val_loss: 0.0040 - 55ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0037 - 52ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0034 - 55ms/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0032 - 52ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "24/24 - 0s - loss: 0.0012 - val_loss: 0.0030 - 50ms/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "24/24 - 0s - loss: 0.0011 - val_loss: 0.0029 - 59ms/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "24/24 - 0s - loss: 0.0011 - val_loss: 0.0027 - 53ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "24/24 - 0s - loss: 9.9631e-04 - val_loss: 0.0026 - 47ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "24/24 - 0s - loss: 9.4567e-04 - val_loss: 0.0025 - 54ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "24/24 - 0s - loss: 9.0159e-04 - val_loss: 0.0024 - 54ms/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "24/24 - 0s - loss: 8.6304e-04 - val_loss: 0.0023 - 51ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.662\n"
     ]
    }
   ],
   "source": [
    "columns = ['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns] = df[columns].apply(lambda x: np.log(x))\n",
    "df[\"Year\"] = df[\"Year\"] - 2000\n",
    "\n",
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value']= min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "                                                                \n",
    "columns_mms=['Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "\n",
    "y = df['Export_Value']\n",
    "X = df.drop('Export_Value',axis=1)\n",
    "\n",
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]\n",
    "\n",
    "timesteps=1\n",
    "train_X = train_X.reshape((train_X.shape[0]//timesteps, timesteps, train_X.shape[1]))\n",
    "validation_X = validation_X.reshape((validation_X.shape[0]//timesteps, timesteps, validation_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0]//timesteps, timesteps, test_X.shape[1]))\n",
    "\n",
    "train_y = train_y.reshape((train_y.shape[0]//timesteps, timesteps,))\n",
    "validation_y = validation_y.reshape((validation_y.shape[0]//timesteps, timesteps,))\n",
    "test_y =  test_y.reshape((test_y.shape[0]//timesteps, timesteps,))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(train_X, train_y, epochs=30, batch_size=None,\n",
    "                    validation_data=(validation_X, validation_y), verbose=2,\n",
    "                    shuffle=False, callbacks=[es])\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()\n",
    "\n",
    "yhat = model.predict(test_X)\n",
    "inv_yhat  = min_max_scaler_y.inverse_transform(yhat) \n",
    "test_y = test_y.reshape((len(test_y)*timesteps, 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y) \n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde1e04-9c4f-43a3-b9f3-835d345477c6",
   "metadata": {},
   "source": [
    "The learning curve of the LSTM one-hot encoding model showed in the plot. The calculated result for root mean squared error (RMSE) is 0.605."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61fc40-740c-44d5-ad3f-9128406efbd6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">6.4.1.3. LSTM Model Using Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815f236-c373-4050-8d06-32f6295c1729",
   "metadata": {},
   "source": [
    "Since one-hot encoding adds too many columns and there are too many 0s in these columns, a label encoding approach has been developed that is similar to one-hot encoding.  \n",
    "\n",
    "Label encoding assigns an integer to variables in the categorical column. It starts the numbering from 0 to the number of unique variables in the column. Unlike one-hot encoding, it changes the value of categorical column itself, instead of adding a new column. However, the model may assume that there is a ranking within the country pairs because it ranked non-ordinal values as country pairs.  \n",
    "\n",
    "In order to apply label encoding, 44 country pairs are created by combining the names of importing and exporting countries. After this process, the Export and Import columns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebaaa116-9c1d-406f-9184-2615deb54cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "      <th>CountryPairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>11191.652</td>\n",
       "      <td>5022.337</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>7861.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandChina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>87202.089</td>\n",
       "      <td>104187.632</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2372.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandFrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>312116.389</td>\n",
       "      <td>262963.856</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2246.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandGermany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>27966.976</td>\n",
       "      <td>34470.260</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>3138.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandItaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>147015.380</td>\n",
       "      <td>120782.848</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4.468986e+11</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>28263.096711</td>\n",
       "      <td>1932.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IcelandNetherlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)    GDP_j(t-1)  \\\n",
       "0  2000     11191.652            5022.337  8.982048e+09  1.093997e+12   \n",
       "1  2000     87202.089          104187.632  8.982048e+09  1.492648e+12   \n",
       "2  2000    312116.389          262963.856  8.982048e+09  2.194204e+12   \n",
       "3  2000     27966.976           34470.260  8.982048e+09  1.252024e+12   \n",
       "4  2000    147015.380          120782.848  8.982048e+09  4.468986e+11   \n",
       "\n",
       "   GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  FTA_2        CountryPairs  \n",
       "0  32381.625236    873.287062  7861.07      0      1        IcelandChina  \n",
       "1  32381.625236  24673.203048  2372.32      0      1       IcelandFrance  \n",
       "2  32381.625236  26725.915218  2246.80      0      1      IcelandGermany  \n",
       "3  32381.625236  21997.624316  3138.62      0      1        IcelandItaly  \n",
       "4  32381.625236  28263.096711  1932.09      0      1  IcelandNetherlands  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")\n",
    "df[\"CountryPairs\"] = df[\"Export\"] + df[\"Import\"]\n",
    "df.drop([\"Export\", \"Import\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00de1d5-e4ff-4598-a436-4477655cff12",
   "metadata": {},
   "source": [
    "LabelEncoder class is applied to CountryPairs column to make labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df5ae4aa-ef77-4c77-9e40-f8d6c14b0f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Export_Value</th>\n",
       "      <th>Export_Value_(t-1)</th>\n",
       "      <th>GDP_i(t-1)</th>\n",
       "      <th>GDP_j(t-1)</th>\n",
       "      <th>GDPPC_i(t-1)</th>\n",
       "      <th>GDPPC_j(t-1)</th>\n",
       "      <th>D_ij</th>\n",
       "      <th>FTA_1</th>\n",
       "      <th>FTA_2</th>\n",
       "      <th>CountryPairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>11191.652</td>\n",
       "      <td>5022.337</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.093997e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>873.287062</td>\n",
       "      <td>7861.07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>87202.089</td>\n",
       "      <td>104187.632</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.492648e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>24673.203048</td>\n",
       "      <td>2372.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>312116.389</td>\n",
       "      <td>262963.856</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>2.194204e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>26725.915218</td>\n",
       "      <td>2246.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>27966.976</td>\n",
       "      <td>34470.260</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>1.252024e+12</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>21997.624316</td>\n",
       "      <td>3138.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>147015.380</td>\n",
       "      <td>120782.848</td>\n",
       "      <td>8.982048e+09</td>\n",
       "      <td>4.468986e+11</td>\n",
       "      <td>32381.625236</td>\n",
       "      <td>28263.096711</td>\n",
       "      <td>1932.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Export_Value  Export_Value_(t-1)    GDP_i(t-1)    GDP_j(t-1)  \\\n",
       "0  2000     11191.652            5022.337  8.982048e+09  1.093997e+12   \n",
       "1  2000     87202.089          104187.632  8.982048e+09  1.492648e+12   \n",
       "2  2000    312116.389          262963.856  8.982048e+09  2.194204e+12   \n",
       "3  2000     27966.976           34470.260  8.982048e+09  1.252024e+12   \n",
       "4  2000    147015.380          120782.848  8.982048e+09  4.468986e+11   \n",
       "\n",
       "   GDPPC_i(t-1)  GDPPC_j(t-1)     D_ij  FTA_1  FTA_2  CountryPairs  \n",
       "0  32381.625236    873.287062  7861.07      0      1             0  \n",
       "1  32381.625236  24673.203048  2372.32      0      1             1  \n",
       "2  32381.625236  26725.915218  2246.80      0      1             2  \n",
       "3  32381.625236  21997.624316  3138.62      0      1             3  \n",
       "4  32381.625236  28263.096711  1932.09      0      1             4  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df[\"CountryPairs\"] = encoder.fit_transform(df[\"CountryPairs\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fcba8ae-1e9a-4f3a-8856-89f360cb58fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "24/24 - 2s - loss: 0.0931 - val_loss: 0.1913 - 2s/epoch - 68ms/step\n",
      "Epoch 2/1000\n",
      "24/24 - 0s - loss: 0.0361 - val_loss: 0.0730 - 60ms/epoch - 3ms/step\n",
      "Epoch 3/1000\n",
      "24/24 - 0s - loss: 0.0259 - val_loss: 0.0539 - 50ms/epoch - 2ms/step\n",
      "Epoch 4/1000\n",
      "24/24 - 0s - loss: 0.0204 - val_loss: 0.0426 - 49ms/epoch - 2ms/step\n",
      "Epoch 5/1000\n",
      "24/24 - 0s - loss: 0.0170 - val_loss: 0.0361 - 46ms/epoch - 2ms/step\n",
      "Epoch 6/1000\n",
      "24/24 - 0s - loss: 0.0144 - val_loss: 0.0315 - 56ms/epoch - 2ms/step\n",
      "Epoch 7/1000\n",
      "24/24 - 0s - loss: 0.0125 - val_loss: 0.0280 - 53ms/epoch - 2ms/step\n",
      "Epoch 8/1000\n",
      "24/24 - 0s - loss: 0.0110 - val_loss: 0.0251 - 54ms/epoch - 2ms/step\n",
      "Epoch 9/1000\n",
      "24/24 - 0s - loss: 0.0098 - val_loss: 0.0224 - 49ms/epoch - 2ms/step\n",
      "Epoch 10/1000\n",
      "24/24 - 0s - loss: 0.0087 - val_loss: 0.0200 - 50ms/epoch - 2ms/step\n",
      "Epoch 11/1000\n",
      "24/24 - 0s - loss: 0.0077 - val_loss: 0.0177 - 50ms/epoch - 2ms/step\n",
      "Epoch 12/1000\n",
      "24/24 - 0s - loss: 0.0068 - val_loss: 0.0155 - 50ms/epoch - 2ms/step\n",
      "Epoch 13/1000\n",
      "24/24 - 0s - loss: 0.0059 - val_loss: 0.0128 - 51ms/epoch - 2ms/step\n",
      "Epoch 14/1000\n",
      "24/24 - 0s - loss: 0.0051 - val_loss: 0.0115 - 56ms/epoch - 2ms/step\n",
      "Epoch 15/1000\n",
      "24/24 - 0s - loss: 0.0046 - val_loss: 0.0105 - 51ms/epoch - 2ms/step\n",
      "Epoch 16/1000\n",
      "24/24 - 0s - loss: 0.0041 - val_loss: 0.0100 - 52ms/epoch - 2ms/step\n",
      "Epoch 17/1000\n",
      "24/24 - 0s - loss: 0.0037 - val_loss: 0.0092 - 59ms/epoch - 2ms/step\n",
      "Epoch 18/1000\n",
      "24/24 - 0s - loss: 0.0035 - val_loss: 0.0087 - 54ms/epoch - 2ms/step\n",
      "Epoch 19/1000\n",
      "24/24 - 0s - loss: 0.0033 - val_loss: 0.0083 - 52ms/epoch - 2ms/step\n",
      "Epoch 20/1000\n",
      "24/24 - 0s - loss: 0.0032 - val_loss: 0.0079 - 52ms/epoch - 2ms/step\n",
      "Epoch 21/1000\n",
      "24/24 - 0s - loss: 0.0030 - val_loss: 0.0076 - 49ms/epoch - 2ms/step\n",
      "Epoch 22/1000\n",
      "24/24 - 0s - loss: 0.0029 - val_loss: 0.0073 - 52ms/epoch - 2ms/step\n",
      "Epoch 23/1000\n",
      "24/24 - 0s - loss: 0.0028 - val_loss: 0.0071 - 55ms/epoch - 2ms/step\n",
      "Epoch 24/1000\n",
      "24/24 - 0s - loss: 0.0027 - val_loss: 0.0069 - 50ms/epoch - 2ms/step\n",
      "Epoch 25/1000\n",
      "24/24 - 0s - loss: 0.0026 - val_loss: 0.0067 - 52ms/epoch - 2ms/step\n",
      "Epoch 26/1000\n",
      "24/24 - 0s - loss: 0.0026 - val_loss: 0.0065 - 54ms/epoch - 2ms/step\n",
      "Epoch 27/1000\n",
      "24/24 - 0s - loss: 0.0025 - val_loss: 0.0063 - 54ms/epoch - 2ms/step\n",
      "Epoch 28/1000\n",
      "24/24 - 0s - loss: 0.0024 - val_loss: 0.0062 - 54ms/epoch - 2ms/step\n",
      "Epoch 29/1000\n",
      "24/24 - 0s - loss: 0.0024 - val_loss: 0.0060 - 55ms/epoch - 2ms/step\n",
      "Epoch 30/1000\n",
      "24/24 - 0s - loss: 0.0024 - val_loss: 0.0059 - 50ms/epoch - 2ms/step\n",
      "Epoch 31/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0058 - 54ms/epoch - 2ms/step\n",
      "Epoch 32/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0056 - 56ms/epoch - 2ms/step\n",
      "Epoch 33/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0055 - 56ms/epoch - 2ms/step\n",
      "Epoch 34/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0054 - 55ms/epoch - 2ms/step\n",
      "Epoch 35/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0053 - 51ms/epoch - 2ms/step\n",
      "Epoch 36/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0052 - 51ms/epoch - 2ms/step\n",
      "Epoch 37/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0051 - 48ms/epoch - 2ms/step\n",
      "Epoch 38/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0050 - 59ms/epoch - 2ms/step\n",
      "Epoch 39/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0049 - 55ms/epoch - 2ms/step\n",
      "Epoch 40/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0048 - 51ms/epoch - 2ms/step\n",
      "Epoch 41/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0047 - 52ms/epoch - 2ms/step\n",
      "Epoch 42/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0046 - 52ms/epoch - 2ms/step\n",
      "Epoch 43/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0046 - 49ms/epoch - 2ms/step\n",
      "Epoch 44/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0045 - 48ms/epoch - 2ms/step\n",
      "Epoch 45/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0044 - 50ms/epoch - 2ms/step\n",
      "Epoch 46/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0044 - 54ms/epoch - 2ms/step\n",
      "Epoch 47/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0043 - 56ms/epoch - 2ms/step\n",
      "Epoch 48/1000\n",
      "24/24 - 0s - loss: 0.0023 - val_loss: 0.0043 - 59ms/epoch - 2ms/step\n",
      "Epoch 49/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0043 - 65ms/epoch - 3ms/step\n",
      "Epoch 50/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0042 - 64ms/epoch - 3ms/step\n",
      "Epoch 51/1000\n",
      "24/24 - 0s - loss: 0.0022 - val_loss: 0.0042 - 58ms/epoch - 2ms/step\n",
      "Epoch 52/1000\n",
      "24/24 - 0s - loss: 0.0021 - val_loss: 0.0042 - 60ms/epoch - 2ms/step\n",
      "Epoch 53/1000\n",
      "24/24 - 0s - loss: 0.0021 - val_loss: 0.0041 - 54ms/epoch - 2ms/step\n",
      "Epoch 54/1000\n",
      "24/24 - 0s - loss: 0.0020 - val_loss: 0.0041 - 63ms/epoch - 3ms/step\n",
      "Epoch 55/1000\n",
      "24/24 - 0s - loss: 0.0019 - val_loss: 0.0040 - 56ms/epoch - 2ms/step\n",
      "Epoch 56/1000\n",
      "24/24 - 0s - loss: 0.0019 - val_loss: 0.0040 - 60ms/epoch - 2ms/step\n",
      "Epoch 57/1000\n",
      "24/24 - 0s - loss: 0.0018 - val_loss: 0.0039 - 70ms/epoch - 3ms/step\n",
      "Epoch 58/1000\n",
      "24/24 - 0s - loss: 0.0018 - val_loss: 0.0038 - 61ms/epoch - 3ms/step\n",
      "Epoch 59/1000\n",
      "24/24 - 0s - loss: 0.0017 - val_loss: 0.0038 - 50ms/epoch - 2ms/step\n",
      "Epoch 60/1000\n",
      "24/24 - 0s - loss: 0.0017 - val_loss: 0.0037 - 48ms/epoch - 2ms/step\n",
      "Epoch 61/1000\n",
      "24/24 - 0s - loss: 0.0016 - val_loss: 0.0037 - 49ms/epoch - 2ms/step\n",
      "Epoch 62/1000\n",
      "24/24 - 0s - loss: 0.0016 - val_loss: 0.0036 - 53ms/epoch - 2ms/step\n",
      "Epoch 63/1000\n",
      "24/24 - 0s - loss: 0.0016 - val_loss: 0.0036 - 62ms/epoch - 3ms/step\n",
      "Epoch 64/1000\n",
      "24/24 - 0s - loss: 0.0016 - val_loss: 0.0035 - 58ms/epoch - 2ms/step\n",
      "Epoch 65/1000\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0034 - 60ms/epoch - 2ms/step\n",
      "Epoch 66/1000\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0034 - 55ms/epoch - 2ms/step\n",
      "Epoch 67/1000\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0033 - 53ms/epoch - 2ms/step\n",
      "Epoch 68/1000\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0033 - 58ms/epoch - 2ms/step\n",
      "Epoch 69/1000\n",
      "24/24 - 0s - loss: 0.0015 - val_loss: 0.0033 - 55ms/epoch - 2ms/step\n",
      "Epoch 70/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0032 - 55ms/epoch - 2ms/step\n",
      "Epoch 71/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0032 - 53ms/epoch - 2ms/step\n",
      "Epoch 72/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0031 - 50ms/epoch - 2ms/step\n",
      "Epoch 73/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0031 - 55ms/epoch - 2ms/step\n",
      "Epoch 74/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0031 - 56ms/epoch - 2ms/step\n",
      "Epoch 75/1000\n",
      "24/24 - 0s - loss: 0.0014 - val_loss: 0.0031 - 54ms/epoch - 2ms/step\n",
      "Epoch 76/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 52ms/epoch - 2ms/step\n",
      "Epoch 77/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 53ms/epoch - 2ms/step\n",
      "Epoch 78/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 50ms/epoch - 2ms/step\n",
      "Epoch 79/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 54ms/epoch - 2ms/step\n",
      "Epoch 80/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 50ms/epoch - 2ms/step\n",
      "Epoch 81/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 57ms/epoch - 2ms/step\n",
      "Epoch 82/1000\n",
      "24/24 - 0s - loss: 0.0013 - val_loss: 0.0030 - 58ms/epoch - 2ms/step\n",
      "Epoch 83/1000\n",
      "24/24 - 0s - loss: 0.0012 - val_loss: 0.0030 - 52ms/epoch - 2ms/step\n",
      "Epoch 00083: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.670\n"
     ]
    }
   ],
   "source": [
    "columns=['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns]=df[columns].apply(lambda x: np.log(x))\n",
    "df[\"Year\"]= df[\"Year\"] - 2000\n",
    "\n",
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value']= min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "\n",
    "columns_mms=['GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "\n",
    "y = df['Export_Value']\n",
    "X = df.drop('Export_Value',axis=1)\n",
    "\n",
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]\n",
    "\n",
    "timesteps=1\n",
    "train_X = train_X.reshape((train_X.shape[0]//timesteps,timesteps, train_X.shape[1]))\n",
    "validation_X = validation_X.reshape((validation_X.shape[0]//timesteps, timesteps, validation_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0]//timesteps, timesteps, test_X.shape[1]))\n",
    "\n",
    "train_y = train_y.reshape((train_y.shape[0]//timesteps,timesteps,))\n",
    "validation_y = validation_y.reshape((validation_y.shape[0]//timesteps, timesteps,))\n",
    "test_y =  test_y.reshape((test_y.shape[0]//timesteps, timesteps,))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=1000, batch_size=None,\n",
    "                    validation_data=(validation_X, validation_y), verbose=2,\n",
    "                    shuffle=False, callbacks=[es])\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()\n",
    "\n",
    "yhat = model.predict(test_X)\n",
    "inv_yhat  = min_max_scaler_y.inverse_transform(yhat)\n",
    "test_y = test_y.reshape((len(test_y)*timesteps, 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y) #inv_real_data\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854d426-4dac-4443-bbe7-5a8a47bf3c90",
   "metadata": {},
   "source": [
    "The learning curve of the model has been displayed in the plot. The RMSE for the model is calculated as 0.549."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23379b-5276-4727-8fd1-78c47fbb44e8",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#351C75\">6.4.2. Feed-Forward Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6280980-c406-4dbc-a6b1-ce0064f4a7ec",
   "metadata": {},
   "source": [
    "After LSTM models, feed-forward neural network models have been built to determine whether LSTM is better or not for time series when compared to feed-forward neural networks. That is why similar models have also been built with feed-forward neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffe33a-2d67-4e93-99da-e2f8a2592d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:#351C75\">6.4.2.1. Feed-Forward Neural Network Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00b636ad-9bf0-4b73-8b16-40d632e27002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")\n",
    "\n",
    "df[\"Year\"] = df[\"Year\"] - 2000\n",
    "df.drop([\"Export\", \"Import\"], axis=1, inplace=True)\n",
    "\n",
    "columns = ['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns] = df[columns].apply(lambda x: np.log(x))\n",
    "\n",
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value']= min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "\n",
    "columns_mms=['Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "\n",
    "y = df['Export_Value']\n",
    "X = df.drop('Export_Value',axis=1)\n",
    "\n",
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375460ce-316a-4dcb-b65a-7a25c66a09a0",
   "metadata": {},
   "source": [
    "The input_shape argument specifies the number of neurons in the input layer. For activation function, ReLU and linear function is used for hidden layers and output, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee0f9975-5506-49ed-b2aa-5f1b843f569b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8411 - val_loss: 26.0814\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.0600\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0394\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0640 - val_loss: 0.0355\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0310\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0271\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0260\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.0252\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0245\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0239\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0235\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0229\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0222\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0201\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0196\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0192\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0189\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0185\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0173\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0168\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0164\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0160\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0155\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0144\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0141\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0138\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0135\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0126\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0115\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 00106: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiWElEQVR4nO3de3wU9b3/8dcnm0jkIndbBG2w1apACBhtzkEF6qUi1rsWBattLdbaqm31eOkpon20P389qNRa7UGrpcpR+aFUHpWiRbnoo1YEpYhCDypUEcQAcgchyef3x0yyuyG72YTdbHb3/Xw81p2dmZ35TCLv/ea7M98xd0dERApHUbYLEBGRtqXgFxEpMAp+EZECo+AXESkwCn4RkQJTnO0CUtGrVy8vKyvLdhkiIjllyZIlG929d+P5ORH8ZWVlLF68ONtliIjkFDP7V1Pz1dUjIlJgFPwiIgVGwS8iUmByoo9fRNrevn37WLt2LXv27Ml2KdKM0tJS+vXrR0lJSUrrK/hFpElr166lS5culJWVYWbZLkcScHc2bdrE2rVr6d+/f0rvUVePiDRpz5499OzZU6HfzpkZPXv2bNFfZgp+EUlIoZ8bWvp7yuvgf27TZiZ9sDbbZYiItCt5HfzPb97CvWvXZbsMEWmFLVu28MADD7TqvWeddRZbtmxJus6ECROYO3duq7bfWFlZGRs3bkzLttpCXgd/sRk1utGMSE5KFvy1tbVJ3zt79my6deuWdJ0777yT0047rbXl5bQ8D34U/CI56pZbbuG9996joqKCm266ifnz5zNy5Eguu+wyBg0aBMB5553H8ccfz4ABA5gyZUrDe+tb4GvWrOHYY4/lu9/9LgMGDOCMM85g9+7dAFx55ZXMmDGjYf3bb7+doUOHMmjQIFauXAlAdXU1p59+OkOHDuXqq6/mC1/4QrMt+3vuuYeBAwcycOBAJk+eDMDOnTsZPXo0gwcPZuDAgTz11FMNx3jcccdRXl7OjTfemNafXzJ5fTpnBKNGuS9ywGr+PJO69R+ldZtFffpSfPb5CZffddddLF++nKVLlwIwf/58Fi1axPLlyxtOW3zkkUfo0aMHu3fv5oQTTuDCCy+kZ8+ecdtZtWoVTzzxBA899BCXXHIJTz/9NOPGjdtvf7169eKNN97ggQceYNKkSTz88MPccccdfPWrX+XWW29lzpw5cR8uTVmyZAmPPvoor732Gu7OV77yFYYPH87777/PYYcdxnPPPQfA1q1b2bx5MzNnzmTlypWYWbNdU+mU5y1+o1YtfpG8ceKJJ8adq37fffcxePBgqqqq+PDDD1m1atV+7+nfvz8VFRUAHH/88axZs6bJbV9wwQX7rfPKK68wZswYAM4880y6d++etL5XXnmF888/n06dOtG5c2cuuOACXn75ZQYNGsTcuXO5+eabefnll+natSuHHHIIpaWlXHXVVTzzzDN07NixhT+N1stYi9/MDgf+CHweqAOmuPuvzWwi8F2gOlz1NnefnYka1Mcvkh7JWuZtqVOnTg3T8+fPZ+7cubz66qt07NiRESNGNHkue4cOHRqmI5FIQ1dPovUikQg1NTVAcHFUSyRa/+ijj2bJkiXMnj2bW2+9lTPOOIMJEyawaNEiXnzxRZ588knuv/9+XnrppRbtr7Uy2eKvAX7i7scCVcC1ZnZcuOxed68IHxkJfQiC34E6hb9IzunSpQvbt29PuHzr1q10796djh07snLlSv7+97+nvYaTTjqJ6dOnA/DCCy/w6aefJl3/lFNO4U9/+hO7du1i586dzJw5k5NPPpl169bRsWNHxo0bx4033sgbb7zBjh072Lp1K2eddRaTJ09u6NJqCxlr8bv7emB9OL3dzFYAfTO1v6ZEwosaatw5SBeiiOSUnj17MmzYMAYOHMioUaMYPXp03PIzzzyT3/3ud5SXl/PlL3+ZqqqqtNdw++23c+mll/LUU08xfPhw+vTpQ5cuXRKuP3ToUK688kpOPPFEAK666iqGDBnC888/z0033URRURElJSU8+OCDbN++nXPPPZc9e/bg7tx7771prz8Ra+mfMq3aiVkZsBAYCPwYuBLYBiwm+Ktgv49RMxsPjAc44ogjjv/Xv5q8n0BSkz5Yy09Xf8CnJ32FjpFIq+sXKUQrVqzg2GOPzXYZWfXZZ58RiUQoLi7m1Vdf5ZprrmnTlnlLNPX7MrMl7l7ZeN2Mn9VjZp2Bp4Eb3H2bmT0I/Bzw8Plu4NuN3+fuU4ApAJWVla36dKpv8deqp0dEWuGDDz7gkksuoa6ujoMOOoiHHnoo2yWlRUaD38xKCEJ/mrs/A+DuG2KWPwT8OVP7L47p6hERaamjjjqKN998M9tlpF3Gvty1YNSg3wMr3P2emPl9YlY7H1ieqRoU/CIi+8tki38YcDnwlpktDefdBlxqZhUEXT1rgKszVUBEwS8isp9MntXzCtDUqTQZO32zsfoWfy0KfhGRenl/5S6oxS8iEkvBLyJ5o3PnzgCsW7eOiy66qMl1RowYweLFi5NuZ/LkyezatavhdSrDPKdi4sSJTJo06YC3c6DyOvgjYUeTgl+ksBx22GENI2+2RuPgT2WY51yS18Ff3+KvU+6L5Jybb745bjz+iRMncvfdd7Njxw5OPfXUhiGUn3322f3eu2bNGgYOHAjA7t27GTNmDOXl5XzjG9+IG6vnmmuuobKykgEDBnD77bcDwcBv69atY+TIkYwcORKIv9FKU8MuJxv+OZGlS5dSVVVFeXk5559/fsNwEPfdd1/DUM31A8QtWLCAiooKKioqGDJkSNKhLFKR18Myq6tHJD1+8u5qlu3YmdZtlnfuxN1f6p9w+ZgxY7jhhhv4/ve/D8D06dOZM2cOpaWlzJw5k0MOOYSNGzdSVVXFOeeck/C+sw8++CAdO3Zk2bJlLFu2jKFDhzYs+8UvfkGPHj2ora3l1FNPZdmyZVx33XXcc889zJs3j169esVtK9Gwy927d095+Od63/zmN/nNb37D8OHDmTBhAnfccQeTJ0/mrrvuYvXq1XTo0KGhe2nSpEn89re/ZdiwYezYsYPS0tJUf8xNyusWfwQFv0iuGjJkCJ988gnr1q3jH//4B927d+eII47A3bntttsoLy/ntNNO46OPPmLDhg0Jt7Nw4cKGAC4vL6e8vLxh2fTp0xk6dChDhgzh7bff5p133klaU6JhlyH14Z8hGGBuy5YtDB8+HIArrriChQsXNtQ4duxYHn/8cYqLg7b5sGHD+PGPf8x9993Hli1bGua3Vl63+HUev0h6JGuZZ9JFF13EjBkz+Pjjjxu6PaZNm0Z1dTVLliyhpKSEsrKyJodjjtXUXwOrV69m0qRJvP7663Tv3p0rr7yy2e0kG9ss1eGfm/Pcc8+xcOFCZs2axc9//nPefvttbrnlFkaPHs3s2bOpqqpi7ty5HHPMMa3aPuR5i7/hPH4Fv0hOGjNmDE8++SQzZsxoOEtn69atHHrooZSUlDBv3jyaG8DxlFNOYdq0aQAsX76cZcuWAbBt2zY6depE165d2bBhA3/5y18a3pNoSOhEwy63VNeuXenevXvDXwuPPfYYw4cPp66ujg8//JCRI0fyq1/9ii1btrBjxw7ee+89Bg0axM0330xlZWXDrSFbK69b/OrjF8ltAwYMYPv27fTt25c+fYLRXsaOHcvXv/51KisrqaioaLble8011/Ctb32L8vJyKioqGoZMHjx4MEOGDGHAgAEceeSRDBs2rOE948ePZ9SoUfTp04d58+Y1zE807HKybp1Epk6dyve+9z127drFkUceyaOPPkptbS3jxo1j69atuDs/+tGP6NatGz/72c+YN28ekUiE4447jlGjRrV4f7HaZFjmA1VZWenNnXfblJe3bOW0f7zNnPIBjOzeNQOVieQvDcucW1oyLHNed/Woj19EZH95Hfzq4xcR2V9BBL9a/CKtkwtdwdLy31NBBL9G5xRpudLSUjZt2qTwb+fcnU2bNrXooq68PqtHY/WItF6/fv1Yu3Yt1dXV2S5FmlFaWkq/fv1SXj/Pg1/33BVprZKSEvr3z86FW5JZBdHVoxa/iEiUgl9EpMAo+EVECkxeB79G5xQR2V9eB78u4BIR2V9BBL9a/CIiUQp+EZECk9fBX38Bl7p6RESi8jr4i3UBl4jIfgoi+NXVIyISldfBX2SGoeAXEYmV18EPwXg9Cn4Rkai8D/5iMw3LLCISI2PBb2aHm9k8M1thZm+b2fXh/B5m9lczWxU+d89UDQDFpq4eEZFYmWzx1wA/cfdjgSrgWjM7DrgFeNHdjwJeDF9nTLEZNcp9EZEGGQt+d1/v7m+E09uBFUBf4FxgarjaVOC8TNUAwXg9avGLiES1SR+/mZUBQ4DXgM+5+3oIPhyAQxO8Z7yZLTazxQdyB6BiM13AJSISI+PBb2adgaeBG9x9W6rvc/cp7l7p7pW9e/du9f4V/CIi8TIa/GZWQhD609z9mXD2BjPrEy7vA3ySyRqKdTqniEicTJ7VY8DvgRXufk/MolnAFeH0FcCzmaoBoEhn9YiIxMnkzdaHAZcDb5nZ0nDebcBdwHQz+w7wAXBxBmsIu3oyuQcRkdySNPjNrAiocve/tXTD7v4KhLfA2t+pLd1ea6mrR0QkXtKuHnevA+5uo1oyQsEvIhIvlT7+F8zswrDPPuco+EVE4qXSx/9joBNQa2a7Cbpv3N0PyWhlaaJB2kRE4jUb/O7epS0KyRQN0iYiEi+ls3rM7BzglPDlfHf/c+ZKSi9dwCUiEq/ZPn4zuwu4HngnfFwfzssJweic2a5CRKT9SKXFfxZQEZ7hg5lNBd4kw6NqpksRRk1QuoiIkPqVu91iprtmoI6MUVePiEi8VFr8vwTeNLN5BGf0nALcmtGq0kinc4qIxEvlyt06ghupnEAQ/De7+8dtUFtaKPhFROIlDX53rzOzH7j7dILB1XJORIO0iYjESaWP/69mdmN4D90e9Y+MV5YmGqRNRCReKn383w6fr42Z58CR6S8n/dTVIyISL5U+/lvc/ak2qiftdFaPiEi8VEbnvDbZOu2dxuoREYmX9338EY3VIyISR338IiIFJpXROfu3RSGZouAXEYmXsKvHzP4jZvriRst+mcmi0qlY5/GLiMRJ1sc/Jma68RANZ2agloyIoPP4RURiJQt+SzDd1Ot2S109IiLxkgW/J5hu6nW7peAXEYmX7MvdwWa2jaB1f3A4Tfi6NOOVpUmxGQ7UuVOUm/eLFxFJq4TB7+6RtiwkUyJh2Ncq+EVEgNRvxJKzisOsV3ePiEgg74O/vsWv++6KiATyPviLG4JfyS8iAgUQ/BEFv4hInIRf7prZdpKctunuh2SkojSrb/FroDYRkUCys3q6AJjZncDHwGMEp3KOBbo0t2EzewQ4G/jE3QeG8yYC3wWqw9Vuc/fZB1B/s9TVIyISL5Wunq+5+wPuvt3dt7n7g8CFKbzvDzQ9tMO97l4RPjIa+qDgFxFpLJXgrzWzsWYWMbMiMxsL1Db3JndfCGw+4AoPUESnc4qIxEkl+C8DLgE2hI+Lw3mt9QMzW2Zmj5hZ90Qrmdl4M1tsZourq6sTrdashj5+5b6ICJBC8Lv7Gnc/1917uXtvdz/P3de0cn8PAl8EKoD1wN1J9jvF3SvdvbJ3796t3F1s8Cv5RUQgheA3s6PN7EUzWx6+Ljez/2zNztx9g7vXhvfyfQg4sTXbaQn18YuIxEulq+chgvH49wG4+zLix+pPmZn1iXl5PrC8NdtpiSIU/CIisVK5525Hd19k8QOc1TT3JjN7AhgB9DKztcDtwAgzqyC4PmANcHUL620xdfWIiMRLJfg3mtkXCS/mMrOLCPrnk3L3S5uY/fuWlXfg1NUjIhIvleC/FpgCHGNmHwGrCS7iygkKfhGReEmD38wiwDXufpqZdQKK3H1725SWHtFhmbNbh4hIe5E0+N291syOD6d3tk1J6RVRH7+ISJxUunreNLNZwP8DGsLf3Z/JWFVppK4eEZF4qQR/D2AT8NWYeQ4o+EVEclCzwe/u32qLQjJFwzKLiMRrNvjNrBT4DjAAKK2f7+7fzmBdaVM/SJv6+EVEAqlcufsY8Hnga8ACoB+QM2f26J67IiLxUgn+L7n7z4Cd7j4VGA0MymxZ6aM+fhGReKkE/77weYuZDQS6AmUZqyjNFPwiIvFSOatnSjhu/s+AWUBnYEJGq0qjiAZpExGJk8pZPQ+HkwuAIzNbTvppkDYRkXipnNXTZOve3e9Mfznpp64eEZF4qXT1xA7VUAqcDazITDnpp+AXEYmXSldP3O0RzWwSQV9/TtDN1kVE4qVyVk9jHcmhvn7dbF1EJF4qffxvQcN4BxGgN5AT/fugL3dFRBpLpY//7JjpGmCDuzd768X2Qn38IiLxUgn+xsMzHBJ7/11335zWitKsSMEvIhInleB/Azgc+BQwoBvwQbjMyYH+/mIzjc4pIhJK5cvdOcDX3b2Xu/ck6Pp5xt37u3u7D30Igl8tfhGRQCrBf4K7z65/4e5/AYZnrqT0KzZ19YiI1Eulq2ejmf0n8DhB1844gjty5YygxZ/tKkRE2odUWvyXEpzCORP4E3BoOC9nRDCdzikiEkrlyt3NwPUA4SidW9xzK0XVxy8iEpWwxW9mE8zsmHC6g5m9BLwLbDCz09qqwHQoNrX4RUTqJevq+Qbwz3D6inDdQwm+2P1lhutKK7X4RUSikgX/3pguna8BT7h7rbuvILUvhduNItNYPSIi9ZIF/2dmNtDMegMjgRdilnXMbFnppRa/iEhUsuC/HpgBrATudffVAGZ2FvBmcxs2s0fM7BMzWx4zr4eZ/dXMVoXP3Q+w/pQo+EVEohIGv7u/5u7HuHtPd/95zPzZ7p7K6Zx/AM5sNO8W4EV3Pwp4MXydcQp+EZGo1ozHnxJ3Xwg0HsDtXGBqOD0VOC9T+48V0Vg9IiINMhb8CXzO3dcDhM+HJlrRzMab2WIzW1xdXX1AO1WLX0Qkqq2DP2XuPsXdK929snfv3ge0LQW/iEhUSqdlmtm/A2Wx67v7H1uxvw1m1sfd15tZH+CTVmyjxXQBl4hIVCq3XnwM+CKwFKgNZzvQmuCfRXAx2F3h87Ot2EaLRUCDtImIhFJp8VcCx7V0fB4zewIYAfQys7XA7QSBP93MvkNwM5eLW1Zu60TM2FtX1xa7EhFp91IJ/uXA54H1LdlwklM+T23JdtJBffwiIlGpBH8v4B0zWwR8Vj/T3c/JWFVppuAXEYlKJfgnZrqITIso+EVEGqQyHv+Ctigkk4oNndUjIhJq9jx+M6sys9fNbIeZ7TWzWjPb1hbFpYtuvSgiEpXKBVz3E9xqcRVwMHBVOC9nqI9fRCQqpQu43P1dM4u4ey3wqJn9LcN1pZUu4BIRiUol+HeZ2UHAUjP7FcFpnZ0yW1Z6aZA2EZGoVLp6Lg/X+wGwEzgcuDCTRaWbzuoREYlK5ayef5nZwUAfd7+jDWpKO/Xxi4hEpXJWz9cJxumZE76uMLNZGa4rrRT8IiJRqXT1TAROBLYAuPtSgpE6c0YE3WxdRKReKsFf4+5bM15JBqnFLyISldIgbWZ2GRAxs6OA64CcO51TwS8iEkilxf9DYADBAG1PANuAGzJYU9op+EVEolI5q2cX8NPwkZMiZjhQ506RWbbLERHJqoTB39yZO7k2LDMEA7Up+EWk0CVr8f8b8CFB985rQM4mZnFYeY07JdktRUQk65IF/+eB0wkGaLsMeA54wt3fbovC0ikStvI1QqeISJIvd9291t3nuPsVQBXwLjDfzH7YZtWlSX3wa7weEZFmvtw1sw7AaIJWfxlwH/BM5stKr+KGFr+CX0Qk2Ze7U4GBwF+AO9x9eZtVlWYKfhGRqGQt/ssJRuM8GrjOomfDGODufkiGa0sbBb+ISFTC4Hf3VC7uygkKfhGRqLwJ92Qi4R8rGqhNRKRAgl8tfhGRqIIKft13V0SkwIJfLX4RkQIJ/iLU4hcRqVcQwa8Wv4hIVCo3Ykk7M1sDbAdqCe7wVZnJ/Sn4RUSishL8oZHuvrEtdqTgFxGJKoiuHp3HLyISla3gd+AFM1tiZuObWsHMxpvZYjNbXF1dfUA7U4tfRCQqW8E/zN2HAqOAa83slMYruPsUd69098revXsf0M4U/CIiUVkJfndfFz5/AswETszk/hT8IiJRbR78ZtbJzLrUTwNnABkd8lk3YhERicrGWT2fA2aGwzwXA//j7nMyucPihi93FfwiIm0e/O7+PjC4Lfepe+6KiEQVxOmc6uMXEYkqiOCPaKweEZEGBRH8avGLiEQp+EVECoyCX0SkwCj4RUQKTEEEvwZpExGJKojgV4tfRCSqoIJfp3OKiBRY8KvFLyJSIMFfpEHaREQaFETwQ9DqV4tfRETBLyJScAoo+NXHLyICBRT8EUzn8YuIUEDBr64eEZGAgl9EpMAUVPDrAi4RkQIK/ojpyl0RESio4Dfdc1dEhAIKfvXxi4gEFPwiIgWmYII/YqaxekREKKDgV4tfRCSQ18Hv+/ZR99GHgIJfRKReXgd/zcyn2Pfof+N7div4RURCeR38kWHDYddOahe8FF7Ale2KRESyL6+Dv6jv4RQNHkrt3xZQVFujC7hERMjz4AcoPv0sqKsjsnmTunpERMhS8JvZmWb2TzN718xuyei+evQkUjWMyLat7Nu7N5O7EhHJCcVtvUMziwC/BU4H1gKvm9ksd38nU/uMjDyD4jnPs/XTzbz51DS6du1Kh06diRx8MJHSgyk+6CAiJSUUlZQQiZRgkSIikQhWVBQ8rAiLFIEZWP0zgEWnraj+APd7tvppEZF2oM2DHzgReNfd3wcwsyeBc4GMBb917ES3ww5n1Wf7qDq4fzCzDthZCzt3tHx77ljMdMP82HXipj1cN7rMSPA+j74n0fZIMN+a6MpKWFMKdSfeTtNdZk291zz58v23ZwnmN7OfRNtO0LuXaNupaO5jPJWP+ZY0BZr6vaa6lQM5ztbtMf3aU7MpG7Xc/4V+nHzssWndZjaCvy/wYczrtcBXGq9kZuOB8QBHHHHEAe/015VDGLttOztqa9m6r4a9e/dSu3cvNfv2UltTQ11tLbV1tdTV1lHnTp07HvPAHYfgtdHwuj5ZvP4fpxP+U4v5r4PHvI79d+wxUzGbiPvnGv9PN+YdTW4ndp43ubwuwfsSRURq6zSxJG4/1uQCb3p2SrW0Zt3WzE91+QGv09SPMGgltGpviffTug8DT1vspb7/9vStXLZq6dShNO3bzEbwN/V/z34/U3efAkwBqKysPOCfebfiYs7o0f1ANyMikvOy8eXuWuDwmNf9gHVZqENEpCBlI/hfB44ys/5mdhAwBpiVhTpERApSm3f1uHuNmf0AeB6IAI+4+9ttXYeISKHKRh8/7j4bmJ2NfYuIFLq8v3JXRETiKfhFRAqMgl9EpMAo+EVECox5DoxYaWbVwL9a+fZewMY0ltNe6Tjzi44zv2TrOL/g7r0bz8yJ4D8QZrbY3SuzXUem6Tjzi44zv7S341RXj4hIgVHwi4gUmEII/inZLqCN6Djzi44zv7Sr48z7Pn4REYlXCC1+ERGJoeAXESkweR38bXlT97ZkZoeb2TwzW2Fmb5vZ9eH8Hmb2VzNbFT7n/J1nzCxiZm+a2Z/D1/l4jN3MbIaZrQx/p/+Wp8f5o/D/1+Vm9oSZlebLcZrZI2b2iZktj5mX8NjM7NYwl/5pZl9r63rzNvhjbuo+CjgOuNTMjstuVWlTA/zE3Y8FqoBrw2O7BXjR3Y8CXgxf57rrgRUxr/PxGH8NzHH3Y4DBBMebV8dpZn2B64BKdx9IMCT7GPLnOP8AnNloXpPHFv5bHQMMCN/zQJhXbSZvg5+Ym7q7+16g/qbuOc/d17v7G+H0doKg6EtwfFPD1aYC52WlwDQxs37AaODhmNn5doyHAKcAvwdw973uvoU8O85QMXCwmRUDHQnuvJcXx+nuC4HNjWYnOrZzgSfd/TN3Xw28S5BXbSafg7+pm7r3zVItGWNmZcAQ4DXgc+6+HoIPB+DQLJaWDpOB/wDqYubl2zEeCVQDj4ZdWg+bWSfy7Djd/SNgEvABsB7Y6u4vkGfH2UiiY8t6NuVz8Kd0U/dcZmadgaeBG9x9W7brSSczOxv4xN2XZLuWDCsGhgIPuvsQYCe5292RUNi/fS7QHzgM6GRm47JbVdZkPZvyOfjz+qbuZlZCEPrT3P2ZcPYGM+sTLu8DfJKt+tJgGHCOma0h6Kb7qpk9Tn4dIwT/n65199fC1zMIPgjy7ThPA1a7e7W77wOeAf6d/DvOWImOLevZlM/Bn7c3dTczI+gTXuHu98QsmgVcEU5fATzb1rWli7vf6u793L2M4Hf3kruPI4+OEcDdPwY+NLMvh7NOBd4hz46ToIunysw6hv//nkrw3VS+HWesRMc2CxhjZh3MrD9wFLCoTStz97x9AGcB/wu8B/w02/Wk8bhOIvjTcBmwNHycBfQkOHtgVfjcI9u1pul4RwB/Dqfz7hiBCmBx+Pv8E9A9T4/zDmAlsBx4DOiQL8cJPEHw3cU+ghb9d5IdG/DTMJf+CYxq63o1ZIOISIHJ564eERFpgoJfRKTAKPhFRAqMgl9EpMAo+EVECoyCX9oVM3Mzuzvm9Y1mNjFN2/6DmV2Ujm01s5+Lw1E25zWaX2Zmu81saczjm2nc74j6UUxFkinOdgEijXwGXGBm/8fdN2a7mHpmFnH32hRX/w7wfXef18Sy99y9In2VibScWvzS3tQQ3J/0R40XNG6xm9mO8HmEmS0ws+lm9r9mdpeZjTWzRWb2lpl9MWYzp5nZy+F6Z4fvj5jZf5nZ62a2zMyujtnuPDP7H+CtJuq5NNz+cjP7v+G8CQQX2P3OzP4r1YM2sx1mdreZvWFmL5pZ73B+hZn9PaxrZv2Y7mb2JTOba2b/CN9Tf4ydLTq2/7TwKlnCn8k74XYmpVqX5KlsX/Gmhx6xD2AHcAiwBugK3AhMDJf9Abgodt3weQSwBehDcDXoR8Ad4bLrgckx759D0OA5iuAKy1JgPPCf4TodCK6i7R9udyfQv4k6DyMYhqA3wV/OLwHnhcvmE4w73/g9ZcBuoldbLwVODpc5MDacngDcH04vA4aH03fGHMtrwPnhdCnBMMcjgK0EY78UAa8SfAj1ILhCtP6CzW7Z/j3rkd2HWvzS7ngw0ugfCW7ckarXPbhPwWcEl8K/EM5/iyBw60139zp3XwW8DxwDnAF808yWEgRqT4IPBoBFHoyZ3tgJwHwPBh2rAaYRjKvfnPfcvSLm8XI4vw54Kpx+HDjJzLoShPSCcP5U4BQz6wL0dfeZAO6+x913xdS71t3rCD5YyoBtwB7gYTO7AKhfVwqUgl/aq8kEfeWdYubVEP4/G3ZhHBSz7LOY6bqY13XEf5fVeIwSJxgm94cxYdzfg7HiIWjxN6WpoXXTKdlYKsn2HftzqAWKww+mEwlGcz2P4K8eKWAKfmmX3H0zMJ0g/OutAY4Pp88FSlqx6YvNrCjsEz+SoAvkeeCacKhrzOzo8GYoybwGDDezXuFt8y4FFjTznmSKgPrvLy4DXnH3rcCnZnZyOP9yYEH4F9FaMzsvrLeDmXVMtOHwvg1d3X02cAPBoHBSwHRWj7RndwM/iHn9EPCsmS0iGO0wUWs8mX8SBPTngO+5+x4ze5igS+SN8C+Japq5BaC7rzezW4F5BC3w2e6eypDCXwy7lOo94u73ERzLADNbQtBP/41w+RUEXxR3JOia+lY4/3Lgv83sToIRIS9Oss8uBD+30rDW/b44l8Ki0TlF2gEz2+HunbNdhxQGdfWIiBQYtfhFRAqMWvwiIgVGwS8iUmAU/CIiBUbBLyJSYBT8IiIF5v8DF/i1qqm/I7sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.773\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(train_X.shape[1],), activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=30,\n",
    "                    validation_data=(validation_X, validation_y),\n",
    "                    verbose=1, shuffle=False, callbacks=[es])\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()\n",
    "\n",
    "yhat = model.predict(test_X)\n",
    "inv_yhat  = min_max_scaler_y.inverse_transform(yhat) \n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y) \n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5e6e0-9058-4fb2-82fe-c38afd9374ac",
   "metadata": {},
   "source": [
    "The learning curve of the model is showed in the plot. The RMSE for the model is 0.945."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ce9ab-c9e9-4de9-95ef-e1c011914ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:#351C75\">6.4.2.2. Feed-Forward Neural Network Model Using One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62a0feb2-f5cd-4c9b-8f94-c8e3afb48e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 40941201895309766033408.0000 - val_loss: 160235541467051851776.0000\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 103024450628843732992.0000 - val_loss: 58352929265606983680.0000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 37518380187902803968.0000 - val_loss: 21250366783143018496.0000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13663055953791025152.0000 - val_loss: 7738740518531629056.0000\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4975669447197982720.0000 - val_loss: 2818213503611961344.0000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1811987878310313984.0000 - val_loss: 1026307517988208640.0000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 659870872617615360.0000 - val_loss: 373749978243268608.0000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 240304914859819008.0000 - val_loss: 136108458503045120.0000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 87511762542264320.0000 - val_loss: 49566551115825152.0000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 31869127635238912.0000 - val_loss: 18050639443525632.0000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11605772580421632.0000 - val_loss: 6573497375522816.0000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4226471157563392.0000 - val_loss: 2393868473466880.0000\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1539152533258240.0000 - val_loss: 871774141022208.0000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 560512660144128.0000 - val_loss: 317473714864128.0000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 204121726517248.0000 - val_loss: 115614320427008.0000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 74334928371712.0000 - val_loss: 42103207886848.0000\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 27070518263808.0000 - val_loss: 15332705042432.0000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9858259615744.0000 - val_loss: 5583705997312.0000\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3590077808640.0000 - val_loss: 2033416142848.0000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1307397062656.0000 - val_loss: 740508172288.0000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 476114288640.0000 - val_loss: 269670629376.0000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 173386366976.0000 - val_loss: 98205835264.0000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 63142039552.0000 - val_loss: 35763593216.0000\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 22994413568.0000 - val_loss: 13024017408.0000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8373868544.0000 - val_loss: 4742954496.0000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3049508864.0000 - val_loss: 1727241728.0000\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1110538496.0000 - val_loss: 629009664.0000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 404424320.0000 - val_loss: 229066592.0000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 147278992.0000 - val_loss: 83419384.0000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 53634512.0000 - val_loss: 30378944.0000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 19532038.0000 - val_loss: 11063185.0000\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7112964.0000 - val_loss: 4028932.7500\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2590318.7500 - val_loss: 1467248.8750\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 943311.3125 - val_loss: 534347.5625\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 343522.5312 - val_loss: 194605.3125\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 125098.8203 - val_loss: 70876.6562\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 45556.2031 - val_loss: 25815.5449\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 16589.5859 - val_loss: 9403.9092\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6041.0737 - val_loss: 3426.2422\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2199.7747 - val_loss: 1248.7217\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 800.9794 - val_loss: 455.3518\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 291.6353 - val_loss: 166.1998\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 106.1805 - val_loss: 60.7600\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 38.6633 - val_loss: 22.2779\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.0875 - val_loss: 8.2131\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.1449 - val_loss: 3.0605\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8927 - val_loss: 1.1656\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 0.4643\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2822 - val_loss: 0.2022\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1027\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0640\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0485\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0419\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0390\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0376\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0369\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0365\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0363\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0362\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0361\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0361\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0360\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020BC68609D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test RMSE: 2.175\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")\n",
    "\n",
    "df[\"CountryPairs\"] = df[\"Export\"] + df[\"Import\"]\n",
    "df.drop([\"Export\", \"Import\"], axis=1, inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "columns = ['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)',\n",
    "           'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns] = df[columns].apply(lambda x: np.log(x))\n",
    "\n",
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value']= min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "\n",
    "columns_mms=['Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "\n",
    "y = df['Export_Value']\n",
    "X = df.drop('Export_Value',axis=1)\n",
    "\n",
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "\n",
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(train_X.shape[1],), activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=30,\n",
    "                    validation_data=(validation_X, validation_y), verbose=1,\n",
    "                    shuffle=False, callbacks=[es])\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()\n",
    "\n",
    "yhat = model.predict(test_X)\n",
    "inv_yhat  = min_max_scaler_y.inverse_transform(yhat) \n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y) \n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e5c22-2017-4f9f-a066-f3bb293afa09",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:#351C75\">6.4.2.3. Feed-Forward Neural Network Model Using Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6544583f-7f26-41a7-8f0f-5b3b51a8e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 23.9415 - val_loss: 0.0891\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0797\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0707\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0630\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0568\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0520\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0482\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0449\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0421\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.0400\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0387\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0376\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0368\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0356\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0321\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0314\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0310\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0306\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0302\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0300\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0301\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0303\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.0307\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020BC89FC940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test RMSE: 2.464\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/export_data_all.csv\")\n",
    "\n",
    "df[\"CountryPairs\"] = df[\"Export\"] + df[\"Import\"]\n",
    "df.drop([\"Export\", \"Import\"], axis=1, inplace=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df[\"CountryPairs\"] = encoder.fit_transform(df[\"CountryPairs\"])\n",
    "df[\"Year\"] = df[\"Year\"] - 2000\n",
    "\n",
    "columns = ['Export_Value', 'Export_Value_(t-1)', 'GDP_i(t-1)',\n",
    "           'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "df[columns] = df[columns].apply(lambda x: np.log(x))\n",
    "\n",
    "min_max_scaler_y = preprocessing.MinMaxScaler()\n",
    "df['Export_Value'] = min_max_scaler_y.fit_transform(pd.DataFrame(df['Export_Value']))\n",
    "\n",
    "columns_mms = ['Export_Value_(t-1)', 'GDP_i(t-1)', 'GDP_j(t-1)','GDPPC_i(t-1)', 'GDPPC_j(t-1)', 'D_ij']\n",
    "min_max_scaler_x = preprocessing.MinMaxScaler()\n",
    "df[columns_mms] = min_max_scaler_x.fit_transform(df[columns_mms])\n",
    "\n",
    "y = df['Export_Value']\n",
    "X = df.drop('Export_Value',axis=1)\n",
    "\n",
    "x_values = X.values\n",
    "y_values = y.values\n",
    "\n",
    "\n",
    "train_row = 748 # between 2000 to 2016\n",
    "val = 836 # between 2017 to 2018\n",
    "\n",
    "train_X = x_values[:train_row, :]\n",
    "validation_X = x_values[train_row:val, :]\n",
    "test_X = x_values[val:, :]\n",
    "\n",
    "train_y = y_values[:train_row]\n",
    "validation_y = y_values[train_row:val]\n",
    "test_y = y_values[val:]\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(train_X.shape[1],), activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=30,\n",
    "                    validation_data=(validation_X, validation_y), verbose=1,\n",
    "                    shuffle=False, callbacks=[es])\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='training loss', color='#f87970')\n",
    "pyplot.plot(history.history['val_loss'], label='validation loss', color='#06c0c5')\n",
    "pyplot.legend()\n",
    "pyplot.xlabel(\"Number of Epochs\")\n",
    "pyplot.ylabel(\"Mean Squared Error\")\n",
    "pyplot.show()\n",
    "\n",
    "yhat = model.predict(test_X)\n",
    "inv_yhat  = min_max_scaler_y.inverse_transform(yhat) \n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = min_max_scaler_y.inverse_transform(test_y) \n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885d6a7-fba9-4458-8d5b-80469a64a0f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <span style=\"color:#351C75\">6.5 Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6137a-fc71-4916-9fdc-2ffa2b490f1b",
   "metadata": {},
   "source": [
    "In this part, commentary has been done about the results of the models in Table 3. The possible reasons for the differences between models are discussed. These results and commentaries are dependent on the dataset used in this project. As a result, the comparison is not common for every dataset and model.  \n",
    "\n",
    "<style>\n",
    "table {\n",
    "  text-align:center;\n",
    "  font-family: arial, sans-serif;\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td{\n",
    "  text-align:left;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "th {\n",
    "  text-align:center;\n",
    "  border: 1px solid black;\n",
    "  padding: 8px;\n",
    "}\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "<table class=\"center\" >\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th><span style=\"color:#351C75\">RMSE Values of Models with LSTM</span></th>\n",
    "    <th><span style=\"color:#351C75\">RMSE Values of Models with Feed-Forward Neural Network</span></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Base</b></td>\n",
    "    <td><center>0.611</td>\n",
    "    <td><center>0.945</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Label Encoding</b></td>\n",
    "    <td><center>0.549</td>\n",
    "    <td><center>1.709</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>One-Hot Encoding</b></td>\n",
    "    <td><center>0.605</td>\n",
    "    <td><center>2.163</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p><center> Table 3: RMSE Values of Each Model </p></center>\n",
    "\n",
    "Since the LSTM base model is unable to recognize country pairs, it may have given worse results compared to one-hot encoding and label encoding. In one-hot and label encoding the categorical data is also included in the model, that is why the models are more accurate.  \n",
    "\n",
    "LSTM one-hot encoding may have generated worse results than LSTM label encoding because one-hot encoding adds extra columns, and the majority of the values are zero. Those extra columns cause data to expand and force the model to handle more columns. The columns with too many zero values create confusion for the model, thus it is not desirable.  \n",
    "\n",
    "Feed-forward neural network models performed worse than LSTM models, as expected, since LSTM is a better choice when working with complex data such as time series.  \n",
    "\n",
    "Label encoding, as previously stated, may have produced poor results since it ranks country pairs when there is no ranking between them.  \n",
    "\n",
    "Since LSTM has the forget gate, the LSTM model is more likely to omit meaningless data such as 0. That is why, when comparing the results of two one-hot encoding models, the one with the feed-forward neural network has worse result than LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076fb9e-5f3a-4445-b791-b3edafa06777",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">7. CONCLUSION</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be701dde-12d1-40cc-882c-98e141ced8dd",
   "metadata": {},
   "source": [
    "In the project, deep learning and time series methods for export data, which is one of the main economic indicators of countries, are examined. The future economic values of exports are predicted by analyzing the relationship between GDP (Gross Domestic Product), GDPPC (Gross Domestic Product Per Capita), agreements such as EFTA-Turkey FTA, and distance between countries.  \n",
    "\n",
    "In order to find the optimal model for the data set and foresee export values, several models have been built. When the results of these models are considered, LSTM models outperform feed-forward neural networks. Therefore, LSTM might be more consistent when it comes to time series. Rather than discover the best common model for time series, the project aims to determine which method performs better specifically for the data we worked on.  \n",
    "\n",
    "Although in our project, we analyze time-series data, LSTM is usually applied to areas such as natural language processing. Sentiment analysis, topic classification, and language translation could be performed with LSTM on documents like newspaper articles, book and movie reviews, and tweets. Furthermore, LSTM also can be used in speech recognition.  \n",
    "\n",
    "In the fast-changing world of technology development, future studies could develop algorithms that deliver much more relevant and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e5cde-7f4a-4b6f-92fb-7170c81a804f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#351C75\">REFERENCES</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f699f81-382c-49fa-bf7c-3dda711efa5c",
   "metadata": {},
   "source": [
    "[1] Kass, R. E., Amari, S. I., Arai, K., Brown, E. N., Diekman, C. O., Diesmann, M., …, Kramer, M. A. (2018). Introduction, Computational Neuroscience: Mathematical and Statistical Perspective. Retrieved from\n",
    "https://www.annualreviews.org/doi/10.1146/annurev-statistics-041715-033733.  \n",
    "\n",
    "[2] Sivanandam, S. N., Sumathi, S., & Deepa, S. N. (2006). Historical development of neural networks, Introduction to Neural Networks Using Matlab 6.0. 13-14. Retrieved from https://books.google.com.tr/books?hl=tr&lr=&id=jJTN8RPgyXgC&oi=fnd&pg=PR21&dq=S.N.+Sivanandam,+S.+Sumathi,+S.N.+Deepa,+Introduction+to+Neural+Networks+Using+Matlab+6.0+(McGraw+Hill+Education+(India)+Private+Ltd.,+2006)%0A&ots=h1cxOQLyOJ&sig=OWBFNKIPYtnu2uqKPioDly-9oXA&redir_esc=y#v=onepage&q&f=false.  \n",
    "\n",
    "[3] Sejnowski, T. J. (2020, December 1). The unreasonable effectiveness of deep learning in artificial intelligence. PNAS. https://www.pnas.org/content/117/48/30033Ad  \n",
    "\n",
    "[4] James, G., Witten, D., Hastie, T., & Tibshirani R. (2021). Deep learning, An Introduction to Statistical Learning with Application in R. 403-409. Retrieved from https://www.statlearning.com/  \n",
    "\n",
    "[5] Olah, C. (2015, August 27). Understanding LSTM Networks. Colah’s Blog. Retrieved from https://colah.github.io/posts/2015-08-Understanding-LSTMs/  \n",
    "\n",
    "[6] James, G., Witten, D., Hastie, T., & Tibshirani R. (2021). Deep learning, An Introduction to Statistical Learning with Application in R. 421-423. Retrieved from https://www.statlearning.com/  \n",
    "\n",
    "[7] Brownlee, J. (2019, January 11). Vanishing Gradients Problem. Machine Learning Mastery. Retrieved from https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/.  \n",
    "\n",
    "[8] Phi, M. (2018, September 24). Illustrated Guide to LSTM’s and GRU’s: A step by step explanation. Towards Data Science. Retrieved from\n",
    "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21.  \n",
    "\n",
    "[9] Olah, C. (2015, August 27). Understanding LSTM Networks. Colah’s Blog. Retrieved from https://colah.github.io/posts/2015-08-Understanding-LSTMs/.  \n",
    "\n",
    "[10] Republic Of Türkiye Ministry Of Trade (n.d.). EFTA. Trade. Retrieved from  \n",
    "https://www.trade.gov.tr/free-trade-agreements/efta.  \n",
    "\n",
    "\n",
    "[11] Chawla, J. (2021, July 14). Mushroom Classification Using Deep Learning. Medium. Retrieved from https://medium.com/ai-techsystems/mushroom-classification-using-deep-learning-e0154afa4c03.  \n",
    "\n",
    "[12] Brownlee, J. (2017, August 30). Tips for LSTM Input. Machine Learning Mastery. Retrieved from https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/.  \n",
    "\n",
    "[13] Brownlee, J. (2019, February 27). How to use Learning Curves to Diagnose Machine Learning Model Performance. Machine Learning Mastery. Retrieved from https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
